{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all male data across the years based on sections.\n",
    "There are datasets for 2012, 2012-1.5, 2013 and 2014\n",
    "The different sections that will be merged are as follows:\n",
    "**2012**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education (All men 18 and above)\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks\n",
    "10. Section 8: Community Participation and Social Network Membership\n",
    "\n",
    "**2013**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Health\n",
    "10. Section 8: Political Participation and Governance\n",
    "\n",
    "**2014**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks‚Äù\n",
    "10. Section 8: Participation in Social Safety Net\n",
    "11. Section 9: Siblings\n",
    "12. Section 10: Transfers\n",
    "13. Section 11: Health and Nutrition\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedd007-e29c-4664-8c47-81875441e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code block will merge all roaster files across the years.\n",
    "* First, we are going to read the respective files and store them as data frames\n",
    "* Next, we are going to define column mappings that I have already figured out via manual methods\n",
    "* Once the mappings are done per the set rules, we will see the new roaster dataset across the years 1.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "790eea1a-06ba-457e-bba2-c8b8d683ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there are 2 files for this section in multiple years, we will make a standardized single file for sectional merging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the first file\n",
    "df1 = pd.read_excel(r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\13. Section 2 Part 11 Own and Paid livestock work during last 12m\\2014_s2p12_m.xlsx\")\n",
    "# Load the second file\n",
    "df2 = pd.read_excel(r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\13. Section 2 Part 11 Own and Paid livestock work during last 12m\\2014_s2p14_m.xlsx\")\n",
    "\n",
    "\n",
    "# Merge the two files based on a common column\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Drop redundant columns\n",
    "merged_df.drop(merged_df.columns[merged_df.columns.str.contains('Unnamed', case=True)], axis=1, inplace=True)\n",
    "merged_df.drop(merged_df.columns[merged_df.columns.str.contains(' ', case=False)], axis=1, inplace=True)\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('2014_s2p12 & s2p14.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Store excel file locations to variables\n",
    "\n",
    "agri_2013 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\13. Section 2 Part 11 Own and Paid livestock work during last 12m\\2013_s2p10 & s2p11.csv\"\n",
    "agri_2014 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\13. Section 2 Part 11 Own and Paid livestock work during last 12m\\2014_s2p12 & s2p14.csv\"\n",
    "\n",
    "# Read excel files \n",
    "df_2013 = pd.read_csv(agri_2013)\n",
    "df_2014 = pd.read_csv(agri_2014)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code block will be used to standardize column names across the years to avoid discrepancies during the merging process.\n",
    "\n",
    "# Rename columns in df_2013 to df_2014 column names\n",
    "df_2013.rename(columns={\n",
    "    'hid': 'hid',\n",
    "    'round': 'round',\n",
    "    'r_pid': 'r_pid',\n",
    "    's2p10_q1_i': 's2p12_q1',\n",
    "    's2p10_q1_ii': 's2p12_q2',\n",
    "    's2p10_q2_i': 's2p12_q3',\n",
    "    's2p10_q2_ii': 's2p12_q4',\n",
    "    's2p10_q3_i': 's2p12_q5',\n",
    "    's2p10_q3_ii': 's2p12_q6',\n",
    "    's2p10_q4_i': 's2p12_q7',\n",
    "    's2p10_q4_ii': 's2p12_q8',\n",
    "    's2p10_q5_i': 's2p12_q9',\n",
    "    's2p10_q5_ii': 's2p12_q10',\n",
    "    's2p11_q1a': 's2p14_q2',\n",
    "    's2p11_q1b': 's2p14_q3',\n",
    "    's2p11_q1c': 's2p14_q4',\n",
    "    's2p11_q2a': 's2p14_q5',\n",
    "    's2p11_q2b': 's2p14_q6',\n",
    "    's2p11_q2c': 's2p14_q7',\n",
    "    's2p11_q3a': 's2p14_q8',\n",
    "    's2p11_q3b': 's2p14_q9',\n",
    "    's2p11_q3c': 's2p14_q10',\n",
    "    's2p11_q4a': 's2p14_q11',\n",
    "    's2p11_q4b': 's2p14_q12',\n",
    "    's2p11_q4c': 's2p14_q13',\n",
    "    's2p11_q5a': 's2p14_q14',\n",
    "    's2p11_q5b': 's2p14_q15',\n",
    "    's2p11_q5c': 's2p14_q16',\n",
    "\n",
    "    's2p10_q6_i': 'O_OA_HpD',\n",
    "    's2p10_q6_ii': 'O_OA_D_T',\n",
    "    's2p11_q6a': 'P_OA_HpD',\n",
    "    's2p11_q6b': 'P_OA_D_T',\n",
    "    's2p11_q6c': 'P_OA_WpD'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce41949-4ca3-48f4-abc7-a8adf6ad6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column mappings based on the provided positions\n",
    "# Make dictionaries for each year with updated names\n",
    "# replace with 'None' where there are no columns\n",
    "#Here are the updated mapping lists for the given datasets:\n",
    "\n",
    "\n",
    "mapping_2013 = [\n",
    "    \"hid\", \"round\", \"r_pid\", \"s2p12_q1\", \"s2p12_q2\", \"s2p12_q3\",\n",
    "    \"s2p12_q4\", \"s2p12_q5\", \"s2p12_q6\", \"s2p12_q7\", \"s2p12_q8\",\n",
    "    \"s2p12_q9\", \"s2p12_q10\", None, \"s2p14_q2\", \"s2p14_q3\", \"s2p14_q4\", \n",
    "    \"s2p14_q5\", \"s2p14_q6\", \"s2p14_q7\", \"s2p14_q8\", \"s2p14_q9\", \"s2p14_q10\",\n",
    "    \"s2p14_q11\", \"s2p14_q12\", \"s2p14_q13\", \"s2p14_q14\", \"s2p14_q15\", \"s2p14_q16\",\n",
    "    None, None, \"O_OA_HpD\", \"O_OA_D_T\", \"P_OA_HpD\", \"P_OA_D_T\", \"P_OA_WpD\"\n",
    "]\n",
    "\n",
    "mapping_2014 = [\n",
    "    \"hid\", \"round\", \"r_pid\", \"s2p12_q1\", \"s2p12_q2\", \"s2p12_q3\", \"s2p12_q4\",\n",
    "    \"s2p12_q5\", \"s2p12_q6\", \"s2p12_q7\", \"s2p12_q8\", \"s2p12_q9\", \"s2p12_q10\",\n",
    "    \"s2p14_q1\", \"s2p14_q2\", \"s2p14_q3\", \"s2p14_q4\", \"s2p14_q5\", \"s2p14_q6\", \n",
    "    \"s2p14_q7\", \"s2p14_q8\", \"s2p14_q9\", \"s2p14_q10\", \"s2p14_q11\", \"s2p14_q12\",\n",
    "    \"s2p14_q13\", \"s2p14_q14\", \"s2p14_q15\", \"s2p14_q16\", \"s2p14_q17\", \"s2p14_q18\",\n",
    "    None, None, None, None, None\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ff0c33-1b53-44f3-8c0a-858987312571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "\n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c5e935e-167a-4d75-99b2-0410c1a411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to standardize and merge DataFrames\n",
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if col in df.columns:\n",
    "                    print(f\"Appending data for column {col}\")\n",
    "                    merged_data[ref_col].extend(df[col].tolist())\n",
    "                else:\n",
    "                    print(f\"Column {col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcdaad8d-94c6-4602-bc97-0315c84fe3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'r_pid', 's2p12_q1', 's2p12_q2', 's2p12_q3', 's2p12_q4', 's2p12_q5', 's2p12_q6', 's2p12_q7', 's2p12_q8', 's2p12_q9', 's2p12_q10', 'O_OA_HpD', 'O_OA_D_T', 's2p14_q2', 's2p14_q3', 's2p14_q4', 's2p14_q5', 's2p14_q6', 's2p14_q7', 's2p14_q8', 's2p14_q9', 's2p14_q10', 's2p14_q11', 's2p14_q12', 's2p14_q13', 's2p14_q14', 's2p14_q15', 's2p14_q16', 'P_OA_HpD', 'P_OA_D_T', 'P_OA_WpD']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column r_pid\n",
      "Appending data for column s2p12_q1\n",
      "Appending data for column s2p12_q2\n",
      "Appending data for column s2p12_q3\n",
      "Appending data for column s2p12_q4\n",
      "Appending data for column s2p12_q5\n",
      "Appending data for column s2p12_q6\n",
      "Appending data for column s2p12_q7\n",
      "Appending data for column s2p12_q8\n",
      "Appending data for column s2p12_q9\n",
      "Appending data for column s2p12_q10\n",
      "Appending data for column s2p14_q2\n",
      "Appending data for column s2p14_q3\n",
      "Appending data for column s2p14_q4\n",
      "Appending data for column s2p14_q5\n",
      "Appending data for column s2p14_q6\n",
      "Appending data for column s2p14_q7\n",
      "Appending data for column s2p14_q8\n",
      "Appending data for column s2p14_q9\n",
      "Appending data for column s2p14_q10\n",
      "Appending data for column s2p14_q11\n",
      "Appending data for column s2p14_q12\n",
      "Appending data for column s2p14_q13\n",
      "Appending data for column s2p14_q14\n",
      "Appending data for column s2p14_q15\n",
      "Appending data for column s2p14_q16\n",
      "Appending data for column O_OA_HpD\n",
      "Appending data for column O_OA_D_T\n",
      "Appending data for column P_OA_HpD\n",
      "Appending data for column P_OA_D_T\n",
      "Appending data for column P_OA_WpD\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'r_pid', 's2p12_q1', 's2p12_q2', 's2p12_q3', 's2p12_q4', 's2p12_q5', 's2p12_q6', 's2p12_q7', 's2p12_q8', 's2p12_q9', 's2p12_q10', 's2p14_q1', 's2p14_q2', 's2p14_q3', 's2p14_q4', 's2p14_q5', 's2p14_q6', 's2p14_q7', 's2p14_q8', 's2p14_q9', 's2p14_q10', 's2p14_q11', 's2p14_q12', 's2p14_q13', 's2p14_q14', 's2p14_q15', 's2p14_q16', 's2p14_q17', 's2p14_q18']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column r_pid\n",
      "Appending data for column s2p12_q1\n",
      "Appending data for column s2p12_q2\n",
      "Appending data for column s2p12_q3\n",
      "Appending data for column s2p12_q4\n",
      "Appending data for column s2p12_q5\n",
      "Appending data for column s2p12_q6\n",
      "Appending data for column s2p12_q7\n",
      "Appending data for column s2p12_q8\n",
      "Appending data for column s2p12_q9\n",
      "Appending data for column s2p12_q10\n",
      "Appending data for column s2p14_q1\n",
      "Appending data for column s2p14_q2\n",
      "Appending data for column s2p14_q3\n",
      "Appending data for column s2p14_q4\n",
      "Appending data for column s2p14_q5\n",
      "Appending data for column s2p14_q6\n",
      "Appending data for column s2p14_q7\n",
      "Appending data for column s2p14_q8\n",
      "Appending data for column s2p14_q9\n",
      "Appending data for column s2p14_q10\n",
      "Appending data for column s2p14_q11\n",
      "Appending data for column s2p14_q12\n",
      "Appending data for column s2p14_q13\n",
      "Appending data for column s2p14_q14\n",
      "Appending data for column s2p14_q15\n",
      "Appending data for column s2p14_q16\n",
      "Appending data for column s2p14_q17\n",
      "Appending data for column s2p14_q18\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [df_2013, df_2014]\n",
    "mappings = [ mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'hid': 'HID',\n",
    "    'round': 'Survey_Round',\n",
    "    'r_pid': 'PID',\n",
    "    's2p12_q1': 'O_LvsC_HpD',\n",
    "    's2p12_q2': 'O_LvsC_D_T',\n",
    "    's2p12_q3': 'O_Milk_HpD',\n",
    "    's2p12_q4': 'O_Milk_D_T',\n",
    "    's2p12_q5': 'O_DC_HpD',\n",
    "    's2p12_q6': 'O_DC_D_T',\n",
    "    's2p12_q7': 'O_Graz_HpD',\n",
    "    's2p12_q8': 'O_Graz_D_T',\n",
    "    's2p12_q9': 'O_MedC_HpD',\n",
    "    's2p12_q10': 'O_MedC_D_T',\n",
    "    's2p14_q1': 'Emp_Status',\n",
    "    's2p14_q2': 'P_LvsC_HpD',\n",
    "    's2p14_q3': 'P_LvsC_D_T',\n",
    "    's2p14_q4': 'P_LvsC_WpD',\n",
    "    's2p14_q5': 'P_Milk_HpD',\n",
    "    's2p14_q6': 'P_Milk_D_T',\n",
    "    's2p14_q7': 'P_Milk_WpD',\n",
    "    's2p14_q8': 'P_DC_HpD',\n",
    "    's2p14_q9': 'P_DC_D_T',\n",
    "    's2p14_q10': 'P_DC_WpD',\n",
    "    's2p14_q11': 'P_Graz_HpD',\n",
    "    's2p14_q12': 'P_Graz_D_T',\n",
    "    's2p14_q13': 'P_Graz_WpD',\n",
    "    's2p14_q14': 'P_MedC_HpD',\n",
    "    's2p14_q15': 'P_MedC_D_T',\n",
    "    's2p14_q16': 'P_MedC_WpD',\n",
    "    's2p14_q17': 'P_Inc_D_T',\n",
    "    's2p14_q18': 'P_Inc_W_T',\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('merged_Section_2_part_11.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a984fb-cef4-4d9e-9ac9-b680d6f41940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
