{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86754fdb-b6f7-4567-83a9-871a433ff383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path where the data files are located\n",
    "data_folder = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\FemaleMerge\\3. MERGED CSV Sections\"\n",
    "\n",
    "# List of all the file names to be merged\n",
    "file_names = ['14. Level HH Satisfaction_Household-HouseholdMember_Level.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f29892-450c-4e90-b9d5-2fd12da901f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for a single unique identifier\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the list, read it, and concatenate it to the merged DataFrame\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)  # Create the full file path\n",
    "    print(f\"Looking for file: {file_path}\")  # Debug print\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")  # Debug print\n",
    "        df = pd.read_csv(file_path, dtype=str)  # Read the CSV file with all columns as strings to handle mixed data types\n",
    "\n",
    "        # Convert numeric columns to double (if possible)\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='raise', downcast='float')\n",
    "            except ValueError:\n",
    "                # Keep non-convertible columns as strings\n",
    "                pass\n",
    "\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)  # Concatenate the current file's data to the merged DataFrame\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")  # Debug print\n",
    "\n",
    "# Proceed only if merged_df is not empty\n",
    "if not merged_df.empty:\n",
    "    # Define the merge keys\n",
    "    merge_keys = ['HID']\n",
    "    # Filter out merge keys that are not in the DataFrame\n",
    "    available_merge_keys = [key for key in merge_keys if key in merged_df.columns]\n",
    "\n",
    "    # Function to handle aggregation of non-merge key columns\n",
    "    def aggregate_data(group):\n",
    "        # Initialize an empty dictionary to hold aggregated results\n",
    "        agg_dict = {}\n",
    "        for col in group.columns:\n",
    "            if col in available_merge_keys:\n",
    "                # Keep merge keys as they are\n",
    "                agg_dict[col] = group[col].iloc[0]\n",
    "            else:\n",
    "                # For numeric columns, sum the values\n",
    "                if pd.api.types.is_numeric_dtype(group[col]):\n",
    "                    agg_dict[col] = group[col].sum()\n",
    "                else:\n",
    "                    # For string columns, concatenate all values\n",
    "                    agg_dict[col] = ', '.join(group[col].dropna().astype(str).unique())\n",
    "        return pd.Series(agg_dict)\n",
    "\n",
    "    # Check for initial duplicates\n",
    "    initial_duplicates = merged_df[merged_df.duplicated(subset=available_merge_keys, keep=False)]\n",
    "    if not initial_duplicates.empty:\n",
    "        print(f\"Initial duplicates found based on keys {available_merge_keys}:\")\n",
    "        print(initial_duplicates)\n",
    "\n",
    "    # Handle rows with missing keys separately\n",
    "    complete_keys_df = merged_df.dropna(subset=available_merge_keys)\n",
    "    incomplete_keys_df = merged_df[merged_df[available_merge_keys].isnull().any(axis=1)]\n",
    "\n",
    "    # Drop rows with missing merge keys\n",
    "    merged_df.dropna(subset=available_merge_keys, inplace=True)\n",
    "\n",
    "    # Apply aggregation function to each group for rows with complete keys\n",
    "    if not merged_df.empty:\n",
    "        merged_df = merged_df.groupby(available_merge_keys).apply(aggregate_data).reset_index(drop=True)\n",
    "\n",
    "    # Check for duplicates after aggregation\n",
    "    post_aggregation_duplicates = merged_df[merged_df.duplicated(subset=available_merge_keys, keep=False)]\n",
    "    if not post_aggregation_duplicates.empty:\n",
    "        print(f\"Post-aggregation duplicates found based on keys {available_merge_keys}:\")\n",
    "        print(post_aggregation_duplicates)\n",
    "\n",
    "    # Reorder columns to have available merge keys first and then the rest alphabetically\n",
    "    remaining_columns = [col for col in merged_df.columns if col not in available_merge_keys]  # Get columns excluding available merge keys\n",
    "    # Sort the remaining columns alphabetically; put columns starting with digits at the end\n",
    "    sorted_columns = sorted(remaining_columns, key=lambda x: (x[0].isdigit(), x))\n",
    "\n",
    "    # Define the final column order with available merge keys first\n",
    "    column_order = available_merge_keys + sorted_columns\n",
    "    # Reorder the DataFrame columns according to the defined order\n",
    "    merged_df = merged_df[column_order]\n",
    "\n",
    "    # Remove columns that are entirely empty\n",
    "    merged_df.dropna(axis=1, how='all', inplace=True)\n",
    "    # Remove rows that are entirely empty\n",
    "    merged_df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    # Append rows with incomplete keys to the end of the DataFrame\n",
    "    final_df = pd.concat([merged_df, incomplete_keys_df], ignore_index=True)\n",
    "\n",
    "    # Save the merged and processed data to a new CSV file\n",
    "    final_df.to_csv('2. Education_Household-HouseholdMember_Level.csv', index=False)\n",
    "    print(\"Merged data saved successfully!\")\n",
    "else:\n",
    "    print(\"No data to merge and save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66f4afb9-88ff-4058-afa9-f9a684782841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\FemaleMerge\\3. MERGED CSV Sections\\14. Level HH Satisfaction_Household-HouseholdMember_Level.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\FemaleMerge\\3. MERGED CSV Sections\\14. Level HH Satisfaction_Household-HouseholdMember_Level.csv\n",
      "Merged data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the list, read it, and concatenate it to the merged DataFrame\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)  # Create the full file path\n",
    "    print(f\"Looking for file: {file_path}\")  # Debug print\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")  # Debug print\n",
    "        df = pd.read_csv(file_path, dtype=str)  # Read the CSV file with all columns as strings to handle mixed data types\n",
    "\n",
    "        # Convert numeric columns to double (if possible)\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='raise', downcast='float')\n",
    "            except ValueError:\n",
    "                # Keep non-convertible columns as strings\n",
    "                pass\n",
    "\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)  # Concatenate the current file's data to the merged DataFrame\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")  # Debug print\n",
    "\n",
    "# Proceed only if merged_df is not empty\n",
    "if not merged_df.empty:\n",
    "    # Define the merge keys\n",
    "    merge_keys = ['HID', 'PID']\n",
    "    # Filter out merge keys that are not in the DataFrame\n",
    "    available_merge_keys = [key for key in merge_keys if key in merged_df.columns]\n",
    "\n",
    "    # Function to handle aggregation of non-merge key columns\n",
    "    def aggregate_data(group):\n",
    "        # Initialize an empty dictionary to hold aggregated results\n",
    "        agg_dict = {}\n",
    "        for col in group.columns:\n",
    "            if col in available_merge_keys:\n",
    "                # Keep merge keys as they are\n",
    "                agg_dict[col] = group[col].iloc[0]\n",
    "            else:\n",
    "                # For numeric columns, sum the values\n",
    "                if pd.api.types.is_numeric_dtype(group[col]):\n",
    "                    agg_dict[col] = group[col].sum()\n",
    "                else:\n",
    "                    # For string columns, concatenate all values\n",
    "                    agg_dict[col] = ', '.join(group[col].dropna().astype(str).unique())\n",
    "        return pd.Series(agg_dict)\n",
    "\n",
    "    # Handle rows with missing keys separately\n",
    "    complete_keys_df = merged_df.dropna(subset=available_merge_keys)\n",
    "    incomplete_keys_df = merged_df[merged_df[available_merge_keys].isnull().any(axis=1)]\n",
    "\n",
    "    # Drop rows with missing merge keys\n",
    "    merged_df.dropna(subset=available_merge_keys, inplace=True)\n",
    "\n",
    "    # Apply aggregation function to each group for rows with complete keys\n",
    "    if not merged_df.empty:\n",
    "        merged_df = merged_df.groupby(available_merge_keys).apply(aggregate_data).reset_index(drop=True)\n",
    "\n",
    "    # Reorder columns to have available merge keys first and then the rest alphabetically\n",
    "    remaining_columns = [col for col in merged_df.columns if col not in available_merge_keys]  # Get columns excluding available merge keys\n",
    "    # Sort the remaining columns alphabetically; put columns starting with digits at the end\n",
    "    sorted_columns = sorted(remaining_columns, key=lambda x: (x[0].isdigit(), x))\n",
    "\n",
    "    # Define the final column order with available merge keys first\n",
    "    column_order = available_merge_keys + sorted_columns\n",
    "    # Reorder the DataFrame columns according to the defined order\n",
    "    complete_keys_df = complete_keys_df[column_order]\n",
    "\n",
    "    # Remove columns that are entirely empty\n",
    "    complete_keys_df.dropna(axis=1, how='all', inplace=True)\n",
    "    # Remove rows that are entirely empty\n",
    "    complete_keys_df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    # Append rows with incomplete keys to the end of the DataFrame\n",
    "    final_df = pd.concat([complete_keys_df, incomplete_keys_df], ignore_index=True)\n",
    "\n",
    "    # Save the merged and processed data to a new CSV file\n",
    "    final_df.to_csv('14. Level HH Satisfaction_Household-HouseholdMember_Level Updated.csv', index=False)\n",
    "    print(\"Merged data saved successfully!\")\n",
    "else:\n",
    "    print(\"No data to merge and save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c85776-2c14-4ae6-8a80-11526b9ff981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path and the keys to check\n",
    "file_path = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\3. MERGED CSV Sections\\3. Agriculture_Household-HouseholdMember_Level Updated.csv\"\n",
    "merge_keys = ['HID', 'PID']\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Check for duplicates based on the merge keys\n",
    "duplicates = df[df.duplicated(subset=merge_keys, keep=False)]\n",
    "\n",
    "# Print the results\n",
    "if not duplicates.empty:\n",
    "    print(f\"Found duplicates based on the keys {merge_keys}:\")\n",
    "    print(duplicates)\n",
    "    print(f\"\\nTotal number of duplicate rows: {duplicates.shape[0]}\")\n",
    "else:\n",
    "    print(f\"No duplicates found based on the keys {merge_keys}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3082e06-14b5-4ada-b379-645680cbe54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
