{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all PRICES data across the years based on sections.\n",
    "There are datasets for 2012, 2013 and 2014\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcc85c3-5e73-405d-b1e7-4a08cad121ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All files in the respective folder will be converted to CSV format for readability\n",
    "This will be done for all male files across the years\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Path where the .dta files are located\n",
    "folder_path = r'C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\PriceMerge\\1. Merging by Parts\\1. Cover'\n",
    "\n",
    "# Get a list of all .dta files in the specified directory\n",
    "file_list = glob.glob(folder_path + '/*.dta')\n",
    "\n",
    "# Loop through the list of files\n",
    "for file in file_list:\n",
    "    # Read the .dta file into a pandas DataFrame\n",
    "    df = pd.read_stata(file, convert_categoricals=False)\n",
    "    \n",
    "    # Define the output file name by replacing .dta with .xlsx\n",
    "    output_file = file.replace('.dta', '.csv')\n",
    "    \n",
    "    # Write the DataFrame to an Excel file\n",
    "    df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedd007-e29c-4664-8c47-81875441e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code block will merge all \"cover\" files across the years.\n",
    "* First, we are going to read the respective files and store them as data frames\n",
    "* Next, we are going to define column mappings that I have already figured out via manual methods\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Store excel file locations to variables (change it as per your path to file)\n",
    "\n",
    "path_2013=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\PriceMerge\\1. Merging by Parts\\1. Cover\\2013_cover_prices.csv\"\n",
    "path_2014=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\PriceMerge\\1. Merging by Parts\\1. Cover\\2014_cover_page_price.csv\"\n",
    "\n",
    "# Read csv files\n",
    "\n",
    "df_2013 = pd.read_csv(path_2013)\n",
    "df_2014 = pd.read_csv(path_2014)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code block will standardize column names across the years to avoid discrepancies during the merging process.\n",
    "For example, the cover data for 2013 is noth the same as in 2014 data, but they have the same data under their differently named variables. Hence, we decide to rename such columns beforehand\n",
    "We will add the updated name to the mapping dictionaries instead of the original names.\n",
    "'''\n",
    "\n",
    "# Rename columns in df_2013\n",
    "df_2013.rename(columns={\n",
    "    'cid': 'cid',\n",
    "    'round': 'round',\n",
    "    'q1': 'province',\n",
    "    'q2': 'province_id',\n",
    "    'q3': 'district',\n",
    "    'q4': 'district_id',\n",
    "    'q5': 'tehsil',\n",
    "    'q6': 'tehsil_id',\n",
    "    'q7': 'union_council',\n",
    "    'q8': 'uc_id',\n",
    "    'q10': 'mauza_id'\n",
    "}, inplace=True)\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7fb3b4-574e-4f18-a759-92b1d39f205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated mappings\n",
    "mapping_2013 = [\n",
    "    'cid', 'round', 'province', 'province_id', 'district', \n",
    "    'district_id', 'tehsil', 'tehsil_id', 'union_council', \n",
    "    'uc_id', 'mauza_id'\n",
    "]\n",
    "\n",
    "mapping_2014 = [\n",
    "    'cid', 'round', 'province', 'province_id', 'district', \n",
    "    'district_id', 'tehsil', 'tehsil_id', 'union_council', \n",
    "    'uc_id', 'mauza_id'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bdd3969-3848-486d-af74-f8970359b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "   \n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94ea101-d44f-410d-b66e-385775a40df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col.strip()  # Remove leading/trailing whitespace\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if ref_col in df.columns:\n",
    "                    print(f\"Appending data for column {ref_col}\")\n",
    "                    if isinstance(df[ref_col], pd.Series):\n",
    "                        merged_data[ref_col].extend(df[ref_col].tolist())\n",
    "                    elif isinstance(df[ref_col], pd.DataFrame):\n",
    "                        print(f\"Column {ref_col} is duplicated in DataFrame. Appending data for each duplicate.\")\n",
    "                        for _, series in df[ref_col].items():\n",
    "                            merged_data[ref_col].extend(series.tolist())\n",
    "                else:\n",
    "                    print(f\"Column {ref_col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f20b62-3d2f-4c24-b161-c2dd63f1dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['Unnamed: 0', 'cid', 'round', 'province', 'province_id', 'district', 'district_id', 'tehsil', 'tehsil_id', 'union_council', 'uc_id', 'mauza_id']\n",
      "Appending data for column cid\n",
      "Appending data for column round\n",
      "Appending data for column province\n",
      "Appending data for column province_id\n",
      "Appending data for column district\n",
      "Appending data for column district_id\n",
      "Appending data for column tehsil\n",
      "Appending data for column tehsil_id\n",
      "Appending data for column union_council\n",
      "Appending data for column uc_id\n",
      "Appending data for column mauza_id\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'cid', 'round', 'province', 'province_id', 'district', 'district_id', 'tehsil', 'tehsil_id', 'union_council', 'uc_id', 'mauza_id']\n",
      "Appending data for column cid\n",
      "Appending data for column round\n",
      "Appending data for column province\n",
      "Appending data for column province_id\n",
      "Appending data for column district\n",
      "Appending data for column district_id\n",
      "Appending data for column tehsil\n",
      "Appending data for column tehsil_id\n",
      "Appending data for column union_council\n",
      "Appending data for column uc_id\n",
      "Appending data for column mauza_id\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [ df_2013, df_2014]\n",
    "mappings = [mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'cid': 'CID',\n",
    "    'round': 'Survey_Round',\n",
    "    'province': 'P_Name',\n",
    "    'province_id': 'P_ID',\n",
    "    'district': 'D_Name',\n",
    "    'district_id': 'D_ID',\n",
    "    'tehsil': 'T_Name',\n",
    "    'tehsil_id': 'T_ID',\n",
    "    'union_council': 'UC_Name',\n",
    "    'uc_id': 'UC_ID',\n",
    "    'mauza_id': 'M_ID'\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('merged_cover.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7835b-68d4-403c-a884-c36669ec385f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
