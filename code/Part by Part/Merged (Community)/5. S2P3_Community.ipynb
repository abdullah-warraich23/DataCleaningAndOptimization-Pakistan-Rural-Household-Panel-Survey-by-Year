{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Store excel file locations to variables\n",
    "\n",
    "Com_2012 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\CommunityMerge\\1. Merging by Parts\\5. S2P1.3 Governance\\2012_com_s5-q14to22.csv\"\n",
    "Com_2013 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\CommunityMerge\\1. Merging by Parts\\5. S2P1.3 Governance\\2013_s2_q13q24_focus.csv\"\n",
    "Com_2014 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\CommunityMerge\\1. Merging by Parts\\5. S2P1.3 Governance\\2014_s2_q2q16_community.csv\"\n",
    "\n",
    "# Read excel files \n",
    "df_2012 = pd.read_csv(Com_2012)\n",
    "df_2013 = pd.read_csv(Com_2013)\n",
    "df_2014 = pd.read_csv(Com_2014)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code block will be used to standardize column names across the years to avoid discrepancies during the merging process.\n",
    "\n",
    "# Rename columns in df to df_2012 column names\n",
    "df_2012.rename(columns={\n",
    "    'program': 'program_id',\n",
    "    'S5Q6': 's2_q8',\n",
    "    'S5Q7': 's2_q9',\n",
    "    'S5Q11': 's2_q11',\n",
    "    'S5Q8': 'G_Prgm_ILoM',\n",
    "    'S5Q9_1': 'G_Prgm_Purp1',\n",
    "    'S5Q9_2': 'G_Prgm_Purp2',\n",
    "    'S5Q9_3': 'G_Prgm_Purp3',\n",
    "    'S5Q10': 'G_Prgm_Decide',\n",
    "    'S5Q12': 'G_PrgmEffC_5y',\n",
    "    'S5Q13': 'G_Prgm_2007NoHHB',\n",
    "    'round': 'Survey_Round',\n",
    "    'community': 'Community',\n",
    "    'fid': 'FID',\n",
    "    'PROVINCE_ID': 'P_ID',\n",
    "    'DISTRICT_ID': 'D_ID',\n",
    "    'TEHSIL_ID': 'T_ID',\n",
    "    'MAUZA_ID': 'M_ID'\n",
    "}, inplace=True)\n",
    "\n",
    "# Rename columns in df to df_2013 column names\n",
    "df_2013.rename(columns={\n",
    "    'prog_id': 'program_id',\n",
    "    'program_name': 'program_name',\n",
    "    's2_q6': 's2_q8',\n",
    "    's2_q7': 's2_q9',\n",
    "    's2_q8': 'G_Prgm_ILoM',\n",
    "    's2_q9_first': 'G_Prgm_Purp1',\n",
    "    's2_q9_second': 'G_Prgm_Purp2',\n",
    "    's2_q9_third': 'G_Prgm_Purp3',\n",
    "    's2_q10': 'G_Prgm_Decide',\n",
    "    's2_q12': 'G_PrgmEffC_1y'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce41949-4ca3-48f4-abc7-a8adf6ad6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column mappings based on the provided positions\n",
    "# Make dictionaries for each year with updated names\n",
    "# replace with 'None' where there are no columns\n",
    "#Here are the updated mapping lists for the given datasets:\n",
    "\n",
    "\n",
    "mapping_2012 = [\n",
    "    'cid',\n",
    "    'program_id',\n",
    "    None,\n",
    "    's2_q8',\n",
    "    's2_q9',\n",
    "    None,\n",
    "    's2_q11',\n",
    "    'G_Prgm_ILoM',\n",
    "    'G_Prgm_Purp1',\n",
    "    'G_Prgm_Purp2',\n",
    "    'G_Prgm_Purp3',\n",
    "    'G_Prgm_Decide',\n",
    "    None,\n",
    "    'G_PrgmEffC_5y',\n",
    "    'G_Prgm_2007NoHHB',\n",
    "    'Survey_Round',\n",
    "    'Community',\n",
    "    'FID',\n",
    "    'P_ID',\n",
    "    'D_ID',\n",
    "    'T_ID',\n",
    "    'UC_ID',\n",
    "    'M_ID'\n",
    "]\n",
    "\n",
    "mapping_2013 = [\n",
    "     'cid',\n",
    "    'program_id',\n",
    "    'program_name',\n",
    "    's2_q8',\n",
    "    's2_q9',\n",
    "    None,\n",
    "    's2_q11',\n",
    "    'G_Prgm_ILoM',\n",
    "    'G_Prgm_Purp1',\n",
    "    'G_Prgm_Purp2',\n",
    "    'G_Prgm_Purp3',\n",
    "    'G_Prgm_Decide',\n",
    "    'G_PrgmEffC_1y',\n",
    "    None, None, None, None, None, None, None, None, None, None\n",
    "]\n",
    "\n",
    "\n",
    "mapping_2014 = [\n",
    "    'cid',\n",
    "    'program_id',\n",
    "    'program_name',\n",
    "    's2_q8',\n",
    "    's2_q9',\n",
    "    's2_q10',\n",
    "    's2_q11',\n",
    "    None, None, None, None, None, None, None, None, None, None, None, None,\n",
    "    None, None, None, None\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ff0c33-1b53-44f3-8c0a-858987312571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "\n",
    "for col in mapping_2012:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)   \n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c5e935e-167a-4d75-99b2-0410c1a411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col.strip()  # Remove leading/trailing whitespace\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if ref_col in df.columns:\n",
    "                    print(f\"Appending data for column {ref_col}\")\n",
    "                    if isinstance(df[ref_col], pd.Series):\n",
    "                        merged_data[ref_col].extend(df[ref_col].tolist())\n",
    "                    elif isinstance(df[ref_col], pd.DataFrame):\n",
    "                        print(f\"Column {ref_col} is duplicated in DataFrame. Appending data for each duplicate.\")\n",
    "                        for _, series in df[ref_col].items():\n",
    "                            merged_data[ref_col].extend(series.tolist())\n",
    "                else:\n",
    "                    print(f\"Column {ref_col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcdaad8d-94c6-4602-bc97-0315c84fe3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['Unnamed: 0', 'Survey_Round', 'cid', 'Community', 'prog_id', 'prog', 'S5Q14', 'S5Q15', 'S5Q16', 'S5Q17', 'S5Q18', 'S5Q19', 'S5Q20', 'S5Q21A', 'S5Q21B', 'S5Q21C', 'S5Q21D', 'S5Q22A', 'S5Q22B', 'FID', 'P_ID', 'D_ID', 'T_ID', 'UC_ID', 'M_ID']\n",
      "Appending data for column cid\n",
      "Column program_id not found in DataFrame. Adding NaNs.\n",
      "Column s2_q8 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q9 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q11 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_ILoM not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Purp1 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Purp2 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Purp3 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Decide not found in DataFrame. Adding NaNs.\n",
      "Column G_PrgmEffC_5y not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_2007NoHHB not found in DataFrame. Adding NaNs.\n",
      "Appending data for column Survey_Round\n",
      "Appending data for column Community\n",
      "Appending data for column FID\n",
      "Appending data for column P_ID\n",
      "Appending data for column D_ID\n",
      "Appending data for column T_ID\n",
      "Appending data for column UC_ID\n",
      "Appending data for column M_ID\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'cid', 'proj_id', 'proj_name', 's2_q13', 's2_q14', 's2_q15', 's2_q16', 's2_q17', 's2_q18', 's2_q19', 's2_q20', 's2_q21', 's2_q22', 's2_q23_a', 's2_q23_b', 's2_q23_c', 's2_q23_d', 's2_q23_e', 's2_q23_f', 's2_q23_g', 's2_q24_a', 's2_q24_b']\n",
      "Appending data for column cid\n",
      "Column program_id not found in DataFrame. Adding NaNs.\n",
      "Column program_name not found in DataFrame. Adding NaNs.\n",
      "Column s2_q8 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q9 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q11 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_ILoM not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Purp1 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Purp2 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Purp3 not found in DataFrame. Adding NaNs.\n",
      "Column G_Prgm_Decide not found in DataFrame. Adding NaNs.\n",
      "Column G_PrgmEffC_1y not found in DataFrame. Adding NaNs.\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'cid', 's2_activity_id', 's2_activity_name', 's2_q12', 's2_q13', 's2_q14', 's2_q15', 's2_q16']\n",
      "Appending data for column cid\n",
      "Column program_id not found in DataFrame. Adding NaNs.\n",
      "Column program_name not found in DataFrame. Adding NaNs.\n",
      "Column s2_q8 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q9 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q10 not found in DataFrame. Adding NaNs.\n",
      "Column s2_q11 not found in DataFrame. Adding NaNs.\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [df_2012, df_2013, df_2014]\n",
    "mappings = [mapping_2012, mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'cid': 'CID',\n",
    "    'program_id': 'G_Prgm_ID',\n",
    "    'program_name': 'G_Prgm_Name',\n",
    "    's2_q8': 'G_Prgm_M',\n",
    "    's2_q9': 'G_PrgmM_FIntro',\n",
    "    's2_q10': 'G_PrgmM_StillRun',\n",
    "    's2_q11': 'G_PrgmM_NoHHB'\n",
    "}\n",
    "\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('3. merged_S2P3_Governence 3.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a984fb-cef4-4d9e-9ac9-b680d6f41940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
