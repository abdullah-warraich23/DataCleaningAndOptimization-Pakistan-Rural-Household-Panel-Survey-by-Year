{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all male data across the years based on sections.\n",
    "There are datasets for 2012, 2012-1.5, 2013 and 2014\n",
    "The different sections that will be merged are as follows:\n",
    "**2012**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education (All men 18 and above)\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks\n",
    "10. Section 8: Community Participation and Social Network Membership\n",
    "\n",
    "**2013**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Health\n",
    "10. Section 8: Political Participation and Governance\n",
    "\n",
    "**2014**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks‚Äù\n",
    "10. Section 8: Participation in Social Safety Net\n",
    "11. Section 9: Siblings\n",
    "12. Section 10: Transfers\n",
    "13. Section 11: Health and Nutrition\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Store excel file locations to variables\n",
    "\n",
    "credit_2012 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\22. Section 5 Part 2\\2012_5_s6p2.xlsx\"\n",
    "credit_2012_5 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\22. Section 5 Part 2\\2012_s5p2_m.xlsx\"\n",
    "credit_2013 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\22. Section 5 Part 2\\2013_s5p2_m.xlsx\"\n",
    "credit_2014 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\22. Section 5 Part 2\\2014_s5p2_m.xlsx\"\n",
    "\n",
    "# Read excel files \n",
    "df_2012 = pd.read_excel(credit_2012)\n",
    "df_2012_5 = pd.read_excel(credit_2012_5)\n",
    "df_2013 = pd.read_excel(credit_2013)\n",
    "df_2014 = pd.read_excel(credit_2014)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code block will be used to standardize column names across the years to avoid discrepancies during the merging process.\n",
    "\n",
    "# Rename columns in df_2013 to df_2014 column names\n",
    "df_2013.rename(columns={\n",
    "    's5p2_q7a': 's5p2_q8',\n",
    "    's5p2_q8': 's5p2_q10',\n",
    "    's5p2_q9': 's5p2_q11',\n",
    "    's5p2_q10': 's5p2_q12',\n",
    "    's5p2_q11_m': 's5p2_q13_m',\n",
    "    's5p2_q11_y': 's5p2_q13_y',\n",
    "    's5p2_q12': 's5p2_q14',\n",
    "    's5p2_q13': 's5p2_q15',\n",
    "    's5p2_q14': 's5p2_q16',\n",
    "    's5p2_q15': 's5p2_q17',\n",
    "    's5p2_q16': 's5p2_q18',\n",
    "    's5p2_q17': 's5p2_q19',\n",
    "    's5p2_q18': 's5p2_q20',\n",
    "    's5p2_q19': 's5p2_q21'\n",
    "}, inplace=True)\n",
    "\n",
    "# Rename columns in df_2012_5 to df_2014 column names\n",
    "df_2012_5.rename(columns={\n",
    "    'Round': 'round',\n",
    "    'S6P2_LOAN_NUM': 'loan_number',\n",
    "    'S6P2Q1': 's5p2_q1',\n",
    "    'S6P2Q2': 's5p2_q2',\n",
    "    'S6P2Q3': 's5p2_q3',\n",
    "    'S6P2Q4_MONTH': 's5p2_q4_m',\n",
    "    'S6P2Q4_YEAR': 's5p2_q4_y',\n",
    "    'S6P2Q5': 's5p2_q5',\n",
    "    'S6P2Q6': 's5p2_q6',\n",
    "    'S6P2Q7': 's5p2_q7',\n",
    "    'S6P2Q8': 's5p2_q10',\n",
    "    'S6P2Q9': 's5p2_q11',\n",
    "    'S6P2Q10': 's5p2_q12',\n",
    "    'S6P2Q11_MONTH': 's5p2_q13_m',\n",
    "    'S6P2Q11_YEAR': 's5p2_q13_y',\n",
    "    'S6P2Q12': 's5p2_q16',\n",
    "    'S6P2Q13': 's5p2_q17',\n",
    "    'S6P2Q14': 's5p2_q19',\n",
    "    'S6P2Q15': 's5p2_q20',\n",
    "    'S6P2Q16': 's5p2_q21',\n",
    "    'S6P2Q17': 'Loan_Src_Formal',\n",
    "    'S6P2Q18': 'Loan_Src_Formal_SC',\n",
    "    'S6P2Q19A': 'Crop_SL_MI',\n",
    "    'S6P2Q19B1': 'Crop_SL_MI_A',\n",
    "    'S6P2Q19B2': 'Crop_SL_MI_AM',\n",
    "    'S6P2Q19C': 'Crop_SL_MI_Val',\n",
    "    'S6P2Q19D': 'Crop_SL_SI',\n",
    "    'S6P2Q19E1': 'Crop_SL_SI_A',\n",
    "    'S6P2Q19E2': 'Crop_SL_SI_AM',\n",
    "    'S6P2Q19F': 'Crop_SL_SI_Val',\n",
    "    'C_PROVINCE': 'P_ID',\n",
    "    'C_DISTRICT': 'D_ID',\n",
    "    'C_TEHSIL': 'T_ID',\n",
    "    'C_MAUZA': 'M_ID'\n",
    "}, inplace=True)\n",
    "\n",
    "# Rename columns in df_2012 to df_2014 column names\n",
    "df_2012.rename(columns={\n",
    "    'LOAN_ID': 'loan_number',\n",
    "    'S5P2Q1': 's5p2_q1',\n",
    "    'S5P2Q2': 's5p2_q2',\n",
    "    'S5P2Q3': 's5p2_q3',\n",
    "    'S5P2Q4_MONTH': 's5p2_q4_m',\n",
    "    'S5P2Q4_YEAR': 's5p2_q4_y',\n",
    "    'S5P2Q5': 's5p2_q5',\n",
    "    'S5P2Q6': 's5p2_q6',\n",
    "    'S5P2Q7': 's5p2_q7',\n",
    "    'S5P2Q8': 's5p2_q10',\n",
    "    'S5P2Q9': 's5p2_q11',\n",
    "    'S5P2Q10': 's5p2_q12',\n",
    "    'S5P2Q11_MONTH': 's5p2_q13_m',\n",
    "    'S5P2Q11_YEAR': 's5p2_q13_y',\n",
    "    'S5P2Q12': 's5p2_q16',\n",
    "    'S5P2Q13': 's5p2_q17',\n",
    "    'S5P2Q14': 's5p2_q19',\n",
    "    'S5P2Q15': 's5p2_q20',\n",
    "    'S5P2Q16': 's5p2_q21',\n",
    "    'S5P2Q17': 'Loan_Src_InFormal',\n",
    "    'S5P2Q18': 'Loan_Src_InFormal_SC',\n",
    "    'S5P2Q19A': 'Crop_SL_MI',\n",
    "    'S5P2Q19B': 'Crop_SL_MI_A',\n",
    "    'S5P2Q19C': 'Crop_SL_MI_Val',\n",
    "    'S5P2Q19D': 'Crop_SL_SI',\n",
    "    'S5P2Q19E': 'Crop_SL_SI_A',\n",
    "    'S5P2Q19F': 'Crop_SL_SI_Val',\n",
    "    'PROVINCE_ID': 'P_ID',\n",
    "    'DISTRICT_ID': 'D_ID',\n",
    "    'TEHSIL_ID': 'T_ID',\n",
    "    'UC_ID': 'UC_ID',\n",
    "    'MAUZA_ID': 'M_ID'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce41949-4ca3-48f4-abc7-a8adf6ad6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column mappings based on the provided positions\n",
    "# Make dictionaries for each year with updated names\n",
    "# replace with 'None' where there are no columns\n",
    "#Here are the updated mapping lists for the given datasets:\n",
    "\n",
    "\n",
    "mapping_2012 = [\n",
    "    'hid', 'round', None, None, 'loan_number', 's5p2_q1', 's5p2_q2', 's5p2_q3', 's5p2_q4_m', 's5p2_q4_y',\n",
    "    's5p2_q5', 's5p2_q6', 's5p2_q7', None, None, 's5p2_q10', 's5p2_q11', 's5p2_q12', 's5p2_q13_m', 's5p2_q13_y',\n",
    "    None, None, 's5p2_q16', 's5p2_q17', None, 's5p2_q19', 's5p2_q20', 's5p2_q21', None, None,\n",
    "    'Loan_Src_InFormal', 'Loan_Src_InFormal_SC', 'Crop_SL_MI', 'Crop_SL_MI_A', None, 'Crop_SL_MI_Val', 'Crop_SL_SI', 'Crop_SL_SI_A', None,\n",
    "    'Crop_SL_SI_Val', 'P_ID', 'D_ID', 'T_ID', 'UC_ID', 'M_ID', None\n",
    "]\n",
    "\n",
    "mapping_2012_5 = [\n",
    "    'hid', 'round', None, None, 'loan_number', 's5p2_q1', 's5p2_q2', 's5p2_q3', 's5p2_q4_m', 's5p2_q4_y',\n",
    "    's5p2_q5', 's5p2_q6', 's5p2_q7', None, None, 's5p2_q10', 's5p2_q11', 's5p2_q12', 's5p2_q13_m', 's5p2_q13_y',\n",
    "    None, None, 's5p2_q16', 's5p2_q17', None, 's5p2_q19', 's5p2_q20', 's5p2_q21', 'Loan_Src_Formal',\n",
    "    'Loan_Src_Formal_SC',  None, None, 'Crop_SL_MI',\t'Crop_SL_MI_A',\t'Crop_SL_MI_AM',\t'Crop_SL_MI_Val',\n",
    "    'Crop_SL_SI',\t'Crop_SL_SI_A',\t'Crop_SL_SI_AM',\t'Crop_SL_SI_Val'\n",
    "    'P_ID', 'D_ID', 'T_ID', 'UC_ID', 'M_ID', None\n",
    "]\n",
    "\n",
    "\n",
    "mapping_2013= [\n",
    "    'hid', 'round', 's5p2_qa', 's5p2_qb', 'loan_number', 's5p2_q1', 's5p2_q2', 's5p2_q3', 's5p2_q4_m', 's5p2_q4_y',\n",
    "    's5p2_q5', 's5p2_q6', 's5p2_q7', 's5p2_q8', None, 's5p2_q10', 's5p2_q11', 's5p2_q12', 's5p2_q13_m', 's5p2_q13_y',\n",
    "    's5p2_q14', 's5p2_q15', 's5p2_q16', 's5p2_q17', 's5p2_q18', 's5p2_q19', 's5p2_q20', 's5p2_q21',\n",
    "    None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "]\n",
    "\n",
    "\n",
    "mapping_2014 = [\n",
    "    'hid', 'round', 's5p2_qa', 's5p2_qb', 'loan_number', 's5p2_q1', 's5p2_q2', 's5p2_q3', 's5p2_q4_m', 's5p2_q4_y',\n",
    "    's5p2_q5', 's5p2_q6', 's5p2_q7', 's5p2_q8', 's5p2_q9', 's5p2_q10', 's5p2_q11', 's5p2_q12', 's5p2_q13_m', 's5p2_q13_y',\n",
    "    's5p2_q14', 's5p2_q15', 's5p2_q16', 's5p2_q17', 's5p2_q18', 's5p2_q19', 's5p2_q20', 's5p2_q21',\n",
    "    None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9ff0c33-1b53-44f3-8c0a-858987312571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "\n",
    "for col in mapping_2012:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2012_5:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c5e935e-167a-4d75-99b2-0410c1a411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col.strip()  # Remove leading/trailing whitespace\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if ref_col in df.columns:\n",
    "                    print(f\"Appending data for column {ref_col}\")\n",
    "                    if isinstance(df[ref_col], pd.Series):\n",
    "                        merged_data[ref_col].extend(df[ref_col].tolist())\n",
    "                    elif isinstance(df[ref_col], pd.DataFrame):\n",
    "                        print(f\"Column {ref_col} is duplicated in DataFrame. Appending data for each duplicate.\")\n",
    "                        for _, series in df[ref_col].items():\n",
    "                            merged_data[ref_col].extend(series.tolist())\n",
    "                else:\n",
    "                    print(f\"Column {ref_col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcdaad8d-94c6-4602-bc97-0315c84fe3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['Unnamed: 0', 'Round', 'hid', 'C_PROVINCE', 'C_DISTRICT', 'C_TEHSIL', 'C_UC', 'C_MOUZA', 'C_HH_NUM', 'S6P2_LOAN_NUM', 'S6P2Q1', 'S6P2Q2', 'S6P2Q3', 'S6P2Q4_MONTH', 'S6P2Q4_YEAR', 'S6P2Q5', 'S6P2Q6', 'S6P2Q7', 'S6P2Q8', 'S6P2Q9', 'S6P2Q10', 'S6P2Q11_MONTH', 'S6P2Q11_YEAR', 'S6P2Q12', 'S6P2Q13', 'S6P2Q14', 'S6P2Q15', 'S6P2Q16', 'S6P2Q17', 'S6P2Q18', 'S6P2Q19A', 'S6P2Q19B1', 'S6P2Q19B2', 'S6P2Q19C', 'S6P2Q19D', 'S6P2Q19E1', 'S6P2Q19E2', 'S6P2Q19F']\n",
      "Appending data for column hid\n",
      "Column round not found in DataFrame. Adding NaNs.\n",
      "Column loan_number not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q1 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q2 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q3 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q4_m not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q4_y not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q5 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q6 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q7 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q10 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q11 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q12 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q13_m not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q13_y not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q16 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q17 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q19 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q20 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q21 not found in DataFrame. Adding NaNs.\n",
      "Column Loan_Src_InFormal not found in DataFrame. Adding NaNs.\n",
      "Column Loan_Src_InFormal_SC not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI_A not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI_Val not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI_A not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI_Val not found in DataFrame. Adding NaNs.\n",
      "Column P_ID not found in DataFrame. Adding NaNs.\n",
      "Column D_ID not found in DataFrame. Adding NaNs.\n",
      "Column T_ID not found in DataFrame. Adding NaNs.\n",
      "Column UC_ID not found in DataFrame. Adding NaNs.\n",
      "Column M_ID not found in DataFrame. Adding NaNs.\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'LOAN_ID', 'S5P2Q1', 'S5P2Q2', 'S5P2Q3', 'S5P2Q4_MONTH', 'S5P2Q4_YEAR', 'S5P2Q5', 'S5P2Q6', 'S5P2Q7', 'S5P2Q8', 'S5P2Q9', 'S5P2Q10', 'S5P2Q11_MONTH', 'S5P2Q11_YEAR', 'S5P2Q12', 'S5P2Q13', 'S5P2Q14', 'S5P2Q15', 'S5P2Q16', 'S5P2Q17', 'S5P2Q18', 'S5P2Q19A', 'S5P2Q19B', 'S5P2Q19C', 'S5P2Q19D', 'S5P2Q19E', 'S5P2Q19F', 'PROVINCE_ID', 'DISTRICT_ID', 'TEHSIL_ID', 'UC_ID', 'MAUZA_ID']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Column loan_number not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q1 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q2 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q3 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q4_m not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q4_y not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q5 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q6 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q7 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q10 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q11 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q12 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q13_m not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q13_y not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q16 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q17 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q19 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q20 not found in DataFrame. Adding NaNs.\n",
      "Column s5p2_q21 not found in DataFrame. Adding NaNs.\n",
      "Column Loan_Src_Formal not found in DataFrame. Adding NaNs.\n",
      "Column Loan_Src_Formal_SC not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI_A not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI_AM not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_MI_Val not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI_A not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI_AM not found in DataFrame. Adding NaNs.\n",
      "Column Crop_SL_SI_ValP_ID not found in DataFrame. Adding NaNs.\n",
      "Column D_ID not found in DataFrame. Adding NaNs.\n",
      "Column T_ID not found in DataFrame. Adding NaNs.\n",
      "Appending data for column UC_ID\n",
      "Column M_ID not found in DataFrame. Adding NaNs.\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 's5p2_qa', 's5p2_qb', 'loan_number', 's5p2_q1', 's5p2_q2', 's5p2_q3', 's5p2_q4_m', 's5p2_q4_y', 's5p2_q5', 's5p2_q6', 's5p2_q7', 's5p2_q8', 's5p2_q10', 's5p2_q11', 's5p2_q12', 's5p2_q13_m', 's5p2_q13_y', 's5p2_q14', 's5p2_q15', 's5p2_q16', 's5p2_q17', 's5p2_q18', 's5p2_q19', 's5p2_q20', 's5p2_q21']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column s5p2_qa\n",
      "Appending data for column s5p2_qb\n",
      "Appending data for column loan_number\n",
      "Appending data for column s5p2_q1\n",
      "Appending data for column s5p2_q2\n",
      "Appending data for column s5p2_q3\n",
      "Appending data for column s5p2_q4_m\n",
      "Appending data for column s5p2_q4_y\n",
      "Appending data for column s5p2_q5\n",
      "Appending data for column s5p2_q6\n",
      "Appending data for column s5p2_q7\n",
      "Appending data for column s5p2_q8\n",
      "Appending data for column s5p2_q10\n",
      "Appending data for column s5p2_q11\n",
      "Appending data for column s5p2_q12\n",
      "Appending data for column s5p2_q13_m\n",
      "Appending data for column s5p2_q13_y\n",
      "Appending data for column s5p2_q14\n",
      "Appending data for column s5p2_q15\n",
      "Appending data for column s5p2_q16\n",
      "Appending data for column s5p2_q17\n",
      "Appending data for column s5p2_q18\n",
      "Appending data for column s5p2_q19\n",
      "Appending data for column s5p2_q20\n",
      "Appending data for column s5p2_q21\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 's5p2_qa', 's5p2_qb', 'loan_number', 's5p2_q1', 's5p2_q2', 's5p2_q3', 's5p2_q4_m', 's5p2_q4_y', 's5p2_q5', 's5p2_q6', 's5p2_q7', 's5p2_q8', 's5p2_q9', 's5p2_q10', 's5p2_q11', 's5p2_q12', 's5p2_q13_m', 's5p2_q13_y', 's5p2_q14', 's5p2_q15', 's5p2_q16', 's5p2_q17', 's5p2_q18', 's5p2_q19', 's5p2_q20', 's5p2_q21']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column s5p2_qa\n",
      "Appending data for column s5p2_qb\n",
      "Appending data for column loan_number\n",
      "Appending data for column s5p2_q1\n",
      "Appending data for column s5p2_q2\n",
      "Appending data for column s5p2_q3\n",
      "Appending data for column s5p2_q4_m\n",
      "Appending data for column s5p2_q4_y\n",
      "Appending data for column s5p2_q5\n",
      "Appending data for column s5p2_q6\n",
      "Appending data for column s5p2_q7\n",
      "Appending data for column s5p2_q8\n",
      "Appending data for column s5p2_q9\n",
      "Appending data for column s5p2_q10\n",
      "Appending data for column s5p2_q11\n",
      "Appending data for column s5p2_q12\n",
      "Appending data for column s5p2_q13_m\n",
      "Appending data for column s5p2_q13_y\n",
      "Appending data for column s5p2_q14\n",
      "Appending data for column s5p2_q15\n",
      "Appending data for column s5p2_q16\n",
      "Appending data for column s5p2_q17\n",
      "Appending data for column s5p2_q18\n",
      "Appending data for column s5p2_q19\n",
      "Appending data for column s5p2_q20\n",
      "Appending data for column s5p2_q21\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [df_2012, df_2012_5, df_2013, df_2014]\n",
    "mappings = [mapping_2012, mapping_2012_5, mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'hid': 'HID',\n",
    "    'round': 'Survey_Round',\n",
    "    'loan_number': 'Loan_ID',\n",
    "    's5p2_q1': 'Loan_A',\n",
    "    's5p2_q2': 'Loan_src',\n",
    "    's5p2_q3': 'Loan_Purp',\n",
    "    's5p2_q4_m': 'Loan_M',\n",
    "    's5p2_q4_y': 'Loan_Y',\n",
    "    's5p2_q5': 'Loan_Int',\n",
    "    's5p2_q6': 'Loan_AnInt',\n",
    "    's5p2_q7': 'Loan_AF',\n",
    "    's5p2_q8': 'Loan_AF_Res',\n",
    "    's5p2_q9': 'Loan_Ins',\n",
    "    's5p2_q10': 'Loan_Coll',\n",
    "    's5p2_q11': 'Loan_Coll_Type',\n",
    "    's5p2_q12': 'Loan_Rpy_InTime',\n",
    "    's5p2_q13_m': 'Loan_Rpy_M',\n",
    "    's5p2_q13_y': 'Loan_Rpy_Y',\n",
    "    's5p2_q14': 'Loan_rpy',\n",
    "    's5p2_q15': 'Loan_rpy_ResNo',\n",
    "    's5p2_q16': 'Loan_Rpy_Done',\n",
    "    's5p2_q17': 'Loan_Rpy_TPSF',\n",
    "    's5p2_q18': 'Loan_Rpy_T_Kind',\n",
    "    's5p2_q19': 'Loan_Lforgive',\n",
    "    's5p2_q20': 'Loan_Lforgive_A',\n",
    "    's5p2_q21': 'Loan_Rpy_TTBP'\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('merged_Section_5_part_2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a984fb-cef4-4d9e-9ac9-b680d6f41940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
