{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all male data across the years based on sections.\n",
    "There are datasets for 2012, 2012-1.5, 2013 and 2014\n",
    "The different sections that will be merged are as follows:\n",
    "**2012**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education (All men 18 and above)\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks\n",
    "10. Section 8: Community Participation and Social Network Membership\n",
    "\n",
    "**2013**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Health\n",
    "10. Section 8: Political Participation and Governance\n",
    "\n",
    "**2014**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks‚Äù\n",
    "10. Section 8: Participation in Social Safety Net\n",
    "11. Section 9: Siblings\n",
    "12. Section 10: Transfers\n",
    "13. Section 11: Health and Nutrition\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedd007-e29c-4664-8c47-81875441e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code block will merge all roaster files across the years.\n",
    "* First, we are going to read the respective files and store them as data frames\n",
    "* Next, we are going to define column mappings that I have already figured out via manual methods\n",
    "* Once the mappings are done per the set rules, we will see the new roaster dataset across the years 1.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790eea1a-06ba-457e-bba2-c8b8d683ce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there are 2 files for this section in multiple years, we will make a standardized single file for sectional merging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first file\n",
    "df1 = pd.read_excel(r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\9. Section 2 Part 7 LABOUR AND MACHINERY USED IN RABI AND KHARIF\\2013_s2p5_m.xlsx\")\n",
    "\n",
    "# Load the second file\n",
    "df2 = pd.read_excel(r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\9. Section 2 Part 7 LABOUR AND MACHINERY USED IN RABI AND KHARIF\\2013_s2p5_q11_q12_m.xlsx\")\n",
    "\n",
    "# Merge the two files based on a common column\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Drop redundant columns\n",
    "merged_df.drop(merged_df.columns[merged_df.columns.str.contains('Unnamed', case=True)], axis=1, inplace=True)\n",
    "merged_df.drop(merged_df.columns[merged_df.columns.str.contains(' ', case=False)], axis=1, inplace=True)\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('2013_S2P6.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Store excel file locations to variables\n",
    "\n",
    "agri_2012 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\9. Section 2 Part 7 LABOUR AND MACHINERY USED IN RABI AND KHARIF\\2012_s2p5_m.xlsx\"\n",
    "agri_2013 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\9. Section 2 Part 7 LABOUR AND MACHINERY USED IN RABI AND KHARIF\\2013_S2P6.csv\"\n",
    "\n",
    "# Read excel files \n",
    "df_2012 = pd.read_excel(agri_2012)\n",
    "df_2013 = pd.read_csv(agri_2013)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code block will be used to standardize column names across the years to avoid discrepancies during the merging process.\n",
    "\n",
    "# Rename columns in df\n",
    "df_2012.rename(columns={\n",
    "    'crop_code': 'crop_code',\n",
    "    's2p5q1b1': 's2p5_q1a_i',\n",
    "    's2p5q1b2': 's2p5_q1a_ii',\n",
    "    's2p5q1b3': 's2p5_q1a_iii',\n",
    "    's2p5q1c1': 's2p5_q1b_i',\n",
    "    's2p5q1c2': 's2p5_q1b_ii',\n",
    "    's2p5q1c3': 's2p5_q1b_iii',\n",
    "    's2p5q2b1': 's2p5_q2a_i',\n",
    "    's2p5q2b2': 's2p5_q2a_ii',\n",
    "    's2p5q2b3': 's2p5_q2a_iii',\n",
    "    's2p5q2c1': 's2p5_q2b_i',\n",
    "    's2p5q2c2': 's2p5_q2b_ii',\n",
    "    's2p5q2c3': 's2p5_q2b_iii',\n",
    "    's2p5q3b1': 's2p5_q3a_i',\n",
    "    's2p5q3b2': 's2p5_q3a_ii',\n",
    "    's2p5q3b3': 's2p5_q3a_iii',\n",
    "    's2p5q4b1': 's2p5_q4a_i',\n",
    "    's2p5q4b2': 's2p5_q4a_ii',\n",
    "    's2p5q4b3': 's2p5_q4a_iii',\n",
    "    's2p5q5b1': 's2p5_q5a_i',\n",
    "    's2p5q5b2': 's2p5_q5a_ii',\n",
    "    's2p5q5b3': 's2p5_q5a_iii',\n",
    "    's2p5q5c1': 's2p5_q5b_i',\n",
    "    's2p5q5c2': 's2p5_q5b_ii',\n",
    "    's2p5q5c3': 's2p5_q5b_iii',\n",
    "    's2p5q6b1': 's2p5_q6a_i',\n",
    "    's2p5q6b2': 's2p5_q6a_ii',\n",
    "    's2p5q6b3': 's2p5_q6a_iii',\n",
    "    's2p5q6c1': 's2p5_q6b_i',\n",
    "    's2p5q6c2': 's2p5_q6b_ii',\n",
    "    's2p5q6c3': 's2p5_q6b_iii',\n",
    "    's2p5q7b1': 's2p5_q7a_i',\n",
    "    's2p5q7b2': 's2p5_q7a_ii',\n",
    "    's2p5q7b3': 's2p5_q7a_iii',\n",
    "    's2p5q7c1': 's2p5_q7b_i',\n",
    "    's2p5q7c2': 's2p5_q7b_ii',\n",
    "    's2p5q7c3': 's2p5_q7b_iii',\n",
    "    's2p5q8b1': 's2p5_q8a_i',\n",
    "    's2p5q8b2': 's2p5_q8a_ii',\n",
    "    's2p5q8b3': 's2p5_q8a_iii',\n",
    "    's2p5q8c1': 's2p5_q8b_i',\n",
    "    's2p5q8c2': 's2p5_q8b_ii',\n",
    "    's2p5q8c3': 's2p5_q8b_iii',\n",
    "    's2p5q9b1': 's2p5_q9a_i',\n",
    "    's2p5q9b2': 's2p5_q9a_ii',\n",
    "    's2p5q9b3': 's2p5_q9a_iii',\n",
    "    's2p5q9c1': 's2p5_q9b_i',\n",
    "    's2p5q9c2': 's2p5_q9b_ii',\n",
    "    's2p5q9c3': 's2p5_q9b_iii',\n",
    "    'area': 'Area',\n",
    "    'unit': 'Unit',\n",
    "    's2p5q1a1': 'LandPrep_FL_NoP',\n",
    "    's2p5q1a2': 'LandPrep_FL_NoD',\n",
    "    's2p5q2a1': 'Sowing_FL_NoP',\n",
    "    's2p5q2a2': 'Sowing_FL_NoD',\n",
    "    's2p5q3a1': 'Irr_FL_NoP',\n",
    "    's2p5q3a2': 'Irr_FL_NoD',\n",
    "    's2p5q4a1': 'FA_FL_NoP',\n",
    "    's2p5q4a2': 'FA_FL_NoD',\n",
    "    's2p5q5a1': 'PA_CHL_NoP',\n",
    "    's2p5q5a2': 'PA_FL_NoD',\n",
    "    's2p5q6a1': 'Weed_FL_NoP',\n",
    "    's2p5q6a2': 'Weed_FL_NoD',\n",
    "    's2p5q7a1': 'HPS_FL_NoP',\n",
    "    's2p5q7a2': 'HPS_FL_NoD',\n",
    "    's2p5q8a1': 'Thresh_FL_NoP',\n",
    "    's2p5q8a2': 'Thresh_FL_NoD',\n",
    "    's2p5q9a1': 'TnS_FL_NoP',\n",
    "    's2p5q9a2': 'TnS_FL_NoD'\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# df_2013 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce41949-4ca3-48f4-abc7-a8adf6ad6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column mappings based on the provided positions\n",
    "# Make dictionaries for each year with updated names\n",
    "# replace with 'None' where there are no columns\n",
    "#Here are the updated mapping lists for the given datasets:\n",
    "\n",
    "\n",
    "mapping_2012 = [\n",
    "    \"hid\", \"round\", None, \"crop_code\", \n",
    "    \"s2p5_q1a_i\", \"s2p5_q1a_ii\", \"s2p5_q1a_iii\", \"s2p5_q1b_i\", \"s2p5_q1b_ii\", \"s2p5_q1b_iii\", \n",
    "    \"s2p5_q2a_i\", \"s2p5_q2a_ii\", \"s2p5_q2a_iii\", \"s2p5_q2b_i\", \"s2p5_q2b_ii\", \"s2p5_q2b_iii\", \n",
    "    \"s2p5_q3a_i\", \"s2p5_q3a_ii\", \"s2p5_q3a_iii\", \"s2p5_q4a_i\", \"s2p5_q4a_ii\", \"s2p5_q4a_iii\", \n",
    "    \"s2p5_q5a_i\", \"s2p5_q5a_ii\", \"s2p5_q5a_iii\", \"s2p5_q5b_i\", \"s2p5_q5b_ii\", \"s2p5_q5b_iii\", \n",
    "    \"s2p5_q6a_i\", \"s2p5_q6a_ii\", \"s2p5_q6a_iii\", \"s2p5_q6b_i\", \"s2p5_q6b_ii\", \"s2p5_q6b_iii\", \n",
    "    \"s2p5_q7a_i\", \"s2p5_q7a_ii\", \"s2p5_q7a_iii\", \"s2p5_q7b_i\", \"s2p5_q7b_ii\", \"s2p5_q7b_iii\", \n",
    "    \"s2p5_q8a_i\", \"s2p5_q8a_ii\", \"s2p5_q8a_iii\", \"s2p5_q8b_i\", \"s2p5_q8b_ii\", \"s2p5_q8b_iii\", \n",
    "    \"s2p5_q9a_i\", \"s2p5_q9a_ii\", \"s2p5_q9a_iii\", \"s2p5_q9b_i\", \"s2p5_q9b_ii\", \"s2p5_q9b_iii\", \n",
    "    None, None, None, None, None, None, None, \n",
    "    \"Area\", \"Unit\", \n",
    "    \"LandPrep_FL_NoP\", \"LandPrep_FL_NoD\", \n",
    "    \"Sowing_FL_NoP\", \"Sowing_FL_NoD\", \n",
    "    \"Irr_FL_NoP\", \"Irr_FL_NoD\", \n",
    "    \"FA_FL_NoP\", \"FA_FL_NoD\", \n",
    "    \"PA_CHL_NoP\", \"PA_FL_NoD\", \n",
    "    \"Weed_FL_NoP\", \"Weed_FL_NoD\", \n",
    "    \"HPS_FL_NoP\", \"HPS_FL_NoD\", \n",
    "    \"Thresh_FL_NoP\", \"Thresh_FL_NoD\", \n",
    "    \"TnS_FL_NoP\", \"TnS_FL_NoD\"\n",
    "]\n",
    "\n",
    "\n",
    "mapping_2013 = [\n",
    "    \"hid\", \"round\", \"crop_name\", \"crop_code\", \n",
    "    \"s2p5_q1a_i\", \"s2p5_q1a_ii\", \"s2p5_q1a_iii\", \"s2p5_q1b_i\", \"s2p5_q1b_ii\", \"s2p5_q1b_iii\", \n",
    "    \"s2p5_q2a_i\", \"s2p5_q2a_ii\", \"s2p5_q2a_iii\", \"s2p5_q2b_i\", \"s2p5_q2b_ii\", \"s2p5_q2b_iii\", \n",
    "    \"s2p5_q3a_i\", \"s2p5_q3a_ii\", \"s2p5_q3a_iii\", \"s2p5_q4a_i\", \"s2p5_q4a_ii\", \"s2p5_q4a_iii\", \n",
    "    \"s2p5_q5a_i\", \"s2p5_q5a_ii\", \"s2p5_q5a_iii\", \"s2p5_q5b_i\", \"s2p5_q5b_ii\", \"s2p5_q5b_iii\", \n",
    "    \"s2p5_q6a_i\", \"s2p5_q6a_ii\", \"s2p5_q6a_iii\", \"s2p5_q6b_i\", \"s2p5_q6b_ii\", \"s2p5_q6b_iii\", \n",
    "    \"s2p5_q7a_i\", \"s2p5_q7a_ii\", \"s2p5_q7a_iii\", \"s2p5_q7b_i\", \"s2p5_q7b_ii\", \"s2p5_q7b_iii\", \n",
    "    \"s2p5_q8a_i\", \"s2p5_q8a_ii\", \"s2p5_q8a_iii\", \"s2p5_q8b_i\", \"s2p5_q8b_ii\", \"s2p5_q8b_iii\", \n",
    "    \"s2p5_q9a_i\", \"s2p5_q9a_ii\", \"s2p5_q9a_iii\", \"s2p5_q9b_i\", \"s2p5_q9b_ii\", \"s2p5_q9b_iii\", \n",
    "    \"s2p5_q10a_i\", \"s2p5_q10a_ii\", \"s2p5_q10a_iii\", \"s2p5_q11\", \n",
    "    \"s2p5_q12_i\", \"s2p5_q12_ii\", \"s2p5_q12_iii\", \n",
    "    None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ff0c33-1b53-44f3-8c0a-858987312571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "for col in mapping_2012:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8efcdee-5712-45fc-b87d-c896b489fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def standardize_and_merge(dfs, mappings, ref_mapping, df_names):\n",
    "    \"\"\"\n",
    "    Standardize and merge dataframes based on reference mapping.\n",
    "\n",
    "    Parameters:\n",
    "    dfs (list of pd.DataFrame): List of dataframes to be merged.\n",
    "    mappings (list of list): List of mappings corresponding to each dataframe.\n",
    "    ref_mapping (list): Reference mapping to standardize the column names.\n",
    "    df_names (list): List of dataframe names.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The merged dataframe with standardized column names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a dictionary to store columns from all dataframes\n",
    "    merged_data = {col: [] for col in ref_mapping if col}\n",
    "    # Track already included columns\n",
    "    included_cols = set(merged_data.keys())\n",
    "    \n",
    "    max_len = 0  # To track the maximum length of columns\n",
    "\n",
    "    # Iterate through each dataframe and its corresponding mapping\n",
    "    for df, mapping, df_name in zip(dfs, mappings, df_names):\n",
    "        for i, col in enumerate(df.columns):\n",
    "            if col in mapping:\n",
    "                ref_col = ref_mapping[mapping.index(col)]\n",
    "                if ref_col:  # Reference column is not None\n",
    "                    if ref_col in merged_data:\n",
    "                        merged_data[ref_col].extend(df[col].tolist())\n",
    "                    else:\n",
    "                        merged_data[ref_col] = df[col].tolist()\n",
    "                    max_len = max(max_len, len(merged_data[ref_col]))\n",
    "                else:\n",
    "                    # For columns in the dataframes but not in the reference mapping\n",
    "                    new_col_name = f\"{df_name}_{col}\"\n",
    "                    if new_col_name not in included_cols:\n",
    "                        merged_data[new_col_name] = df[col].tolist()\n",
    "                        included_cols.add(new_col_name)\n",
    "                        max_len = max(max_len, len(merged_data[new_col_name]))\n",
    "            else:\n",
    "                # Handle columns not present in the mapping\n",
    "                for j, ref_col in enumerate(ref_mapping):\n",
    "                    if not ref_col:\n",
    "                        new_col_name = f\"{df_name}_{col}\"\n",
    "                        if new_col_name not in included_cols:\n",
    "                            merged_data[new_col_name] = df[col].values.tolist() \n",
    "                            included_cols.add(new_col_name)\n",
    "                            max_len = max(max_len, len(merged_data[new_col_name]))\n",
    "\n",
    "    # Ensure all columns have the same length\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    # Convert the merged_data dictionary to a DataFrame\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    \n",
    "    # Remove columns containing 'Unnamed'\n",
    "    merged_df = merged_df.loc[:, ~merged_df.columns.str.contains('Unnamed')]\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b101a410-2dff-4a7f-bb14-ea098d0f4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes and their mappings\n",
    "dfs = [df_2012, df_2013]\n",
    "mappings = [mapping_2012, mapping_2013]\n",
    "ref_mapping = mapping_2013\n",
    "df_name= ['2012', '2013']\n",
    "merged_df = standardize_and_merge(dfs, mappings, ref_mapping, df_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'hid': 'HID',\n",
    "    'round': 'Survey_Round',\n",
    "    'crop_name': 'CN',\n",
    "    'crop_code': 'CC',\n",
    "    's2p5_q1a_i': 'LandPrep_CHL_NoP',\n",
    "    's2p5_q1a_ii': 'LandPrep_CHL_NoD',\n",
    "    's2p5_q1a_iii': 'LandPrep_CHL_CPP',\n",
    "    's2p5_q1b_i': 'LandPrep_M',\n",
    "    's2p5_q1b_ii': 'LandPrep_M_Status',\n",
    "    's2p5_q1b_iii': 'LandPrep_CoM',\n",
    "    's2p5_q2a_i': 'Sowing_CHL_NoP',\n",
    "    's2p5_q2a_ii': 'Sowing_CHL_NoD',\n",
    "    's2p5_q2a_iii': 'Sowing_CHL_CPP',\n",
    "    's2p5_q2b_i': 'Sowing_M',\n",
    "    's2p5_q2b_ii': 'Sowing_M_Status',\n",
    "    's2p5_q2b_iii': 'Sowing_CoM',\n",
    "    's2p5_q3a_i': 'Irr_CHL_NoP',\n",
    "    's2p5_q3a_ii': 'Irr_CHL_NoD',\n",
    "    's2p5_q3a_iii': 'Irr_CHL_CPP',\n",
    "    's2p5_q4a_i': 'FA_CHL_NoP',\n",
    "    's2p5_q4a_ii': 'FA_CHL_NoD',\n",
    "    's2p5_q4a_iii': 'FA_CHL_CPP',\n",
    "    's2p5_q5a_i': 'PA_CHL_NoP',\n",
    "    's2p5_q5a_ii': 'PA_CHL_NoD',\n",
    "    's2p5_q5a_iii': 'PA_CHL_CPP',\n",
    "    's2p5_q5b_i': 'PA_M',\n",
    "    's2p5_q5b_ii': 'PA_M_Status',\n",
    "    's2p5_q5b_iii': 'PA_CoM',\n",
    "    's2p5_q6a_i': 'Weed_CHL_NoP',\n",
    "    's2p5_q6a_ii': 'Weed_CHL_NoD',\n",
    "    's2p5_q6a_iii': 'Weed_CHL_CPP',\n",
    "    's2p5_q6b_i': 'Weed_M',\n",
    "    's2p5_q6b_ii': 'Weed_M_Status',\n",
    "    's2p5_q6b_iii': 'Weed_CoM',\n",
    "    's2p5_q7a_i': 'HPS_CHL_NoP',\n",
    "    's2p5_q7a_ii': 'HPS_CHL_NoD',\n",
    "    's2p5_q7a_iii': 'HPS_CHL_CPP',\n",
    "    's2p5_q7b_i': 'HPS_M',\n",
    "    's2p5_q7b_ii': 'HPS_M_Status',\n",
    "    's2p5_q7b_iii': 'HPS_CoM',\n",
    "    's2p5_q8a_i': 'Thresh_CHL_NoP',\n",
    "    's2p5_q8a_ii': 'Thresh_CHL_NoD',\n",
    "    's2p5_q8a_iii': 'Thresh_CHL_CPP',\n",
    "    's2p5_q8b_i': 'Thresh_M',\n",
    "    's2p5_q8b_ii': 'Thresh_M_Status',\n",
    "    's2p5_q8b_iii': 'Thresh_CoM',\n",
    "    's2p5_q9a_i': 'TnS_CHL_NoP',\n",
    "    's2p5_q9a_ii': 'TnS_CHL_NoD',\n",
    "    's2p5_q9a_iii': 'TnS_CHL_CPP',\n",
    "    's2p5_q9b_i': 'TnS_M',\n",
    "    's2p5_q9b_ii': 'TnS_M_Status',\n",
    "    's2p5_q9b_iii': 'TnS_CoM',\n",
    "    's2p5_q10a_i': 'Prune_CHL_NoP',\n",
    "    's2p5_q10a_ii': 'Prune_CHL_NoD',\n",
    "    's2p5_q10a_iii': 'Prune_CHL_CPP',\n",
    "    's2p5_q11': 'PHL',\n",
    "    's2p5_q12_i': 'PHL_NoP',\n",
    "    's2p5_q12_ii': 'PHL_NoM',\n",
    "    's2p5_q12_iii': 'PHL_CPP'\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('merged_Section_2_part_7.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a984fb-cef4-4d9e-9ac9-b680d6f41940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
