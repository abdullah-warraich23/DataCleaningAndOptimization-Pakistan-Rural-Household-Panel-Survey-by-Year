{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Store excel file locations to variables (change it as per your path to file)\n",
    "file_2012=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\FemaleMerge\\1. Merging by Parts\\4. Section 2 Part 2a&b TIME ALLOCATED TO OWN FARM ACTIVITIES DURING RABI AND KHARIF\\2012_s2p2a2b_f.csv\"\n",
    "file_2013=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\FemaleMerge\\1. Merging by Parts\\4. Section 2 Part 2a&b TIME ALLOCATED TO OWN FARM ACTIVITIES DURING RABI AND KHARIF\\2013_s2p2.csv\"\n",
    "file_2014=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\FemaleMerge\\1. Merging by Parts\\4. Section 2 Part 2a&b TIME ALLOCATED TO OWN FARM ACTIVITIES DURING RABI AND KHARIF\\2014_s2p2.csv\"\n",
    "\n",
    "# Read excel files\n",
    "df_2012 = pd.read_csv(file_2012)\n",
    "df_2013 = pd.read_csv(file_2013)\n",
    "df_2014 = pd.read_csv(file_2014)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code block will be used to standardize column names across the years to avoid discrepancies during the merging process.\n",
    "For example in the roaster data for 2013 rq21 and rq23 are not the same as rq21 and rq23 in 2014 data, but they have the same variable names. Hence, we decide to rename such columns beforehand\n",
    "We will add the updated name to the mapping dictionaries instead of the original names.\n",
    "\n",
    "'''\n",
    "\n",
    "# Rename columns in df_2012\n",
    "df_2012.rename(columns={\n",
    "    'hid': 'hid',\n",
    "    'round': 'round',\n",
    "    'S2P2AQ0': 's2p2a_qa',\n",
    "    'pid': 'r_pid',\n",
    "    'S2P2AQ1A': 's2p2a_q1',\n",
    "    'S2P2AQ1B': 's2p2a_q2',\n",
    "    'S2P2AQ2A': 's2p2a_q3',\n",
    "    'S2P2AQ2B': 's2p2a_q4',\n",
    "    'S2P2AQ3A': 's2p2a_q5',\n",
    "    'S2P2AQ3B': 's2p2a_q6',\n",
    "    'S2P2AQ4A': 's2p2a_q7',\n",
    "    'S2P2AQ4B': 's2p2a_q8',\n",
    "    'S2P2AQ5A': 's2p2a_q9',\n",
    "    'S2P2AQ5B': 's2p2a_q10',\n",
    "    'S2P2BQ0': 's2p2b_qa',\n",
    "    'S2P2BQ1A': 's2p2b_q1',\n",
    "    'S2P2BQ1B': 's2p2b_q2',\n",
    "    'S2P2BQ2A': 's2p2b_q3',\n",
    "    'S2P2BQ2B': 's2p2b_q4',\n",
    "    'S2P2BQ3A': 's2p2b_q5',\n",
    "    'S2P2BQ3B': 's2p2b_q6',\n",
    "    'S2P2BQ4A': 's2p2b_q7',\n",
    "    'S2P2BQ4B': 's2p2b_q8',\n",
    "    'S2P2BQ5A': 's2p2b_q9',\n",
    "    'S2P2BQ5B': 's2p2b_q10'\n",
    "}, inplace=True)\n",
    "\n",
    "# Rename columns in df_2013\n",
    "df_2013.rename(columns={\n",
    "    'hid': 'hid',\n",
    "    'round': 'round',\n",
    "    'pid': 'r_pid',\n",
    "    's2p2a_q1a': 's2p2a_q1',\n",
    "    's2p2a_q1b': 's2p2a_q2',\n",
    "    's2p2a_q2a': 's2p2a_q3',\n",
    "    's2p2a_q2b': 's2p2a_q4',\n",
    "    's2p2a_q3a': 's2p2a_q5',\n",
    "    's2p2a_q3b': 's2p2a_q6',\n",
    "    's2p2a_q4a': 's2p2a_q7',\n",
    "    's2p2a_q4b': 's2p2a_q8',\n",
    "    's2p2a_q5a': 's2p2a_q9',\n",
    "    's2p2a_q5b': 's2p2a_q10',\n",
    "    's2p2b_q1a': 's2p2b_q1',\n",
    "    's2p2b_q1b': 's2p2b_q2',\n",
    "    's2p2b_q2a': 's2p2b_q3',\n",
    "    's2p2b_q2b': 's2p2b_q4',\n",
    "    's2p2b_q3a': 's2p2b_q5',\n",
    "    's2p2b_q3b': 's2p2b_q6',\n",
    "    's2p2b_q4a': 's2p2b_q7',\n",
    "    's2p2b_q4b': 's2p2b_q8',\n",
    "    's2p2b_q5a': 's2p2b_q9',\n",
    "    's2p2b_q5b': 's2p2b_q10'\n",
    "}, inplace=True)\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7fb3b4-574e-4f18-a759-92b1d39f205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated mappings\n",
    "\n",
    "mapping_2012 = [\n",
    "    'hid', 'round', 's2p2a_qa', 'r_pid', 's2p2a_q1', 's2p2a_q2', 's2p2a_q3', 's2p2a_q4', 's2p2a_q5', 's2p2a_q6', \n",
    "    's2p2a_q7', 's2p2a_q8', 's2p2a_q9', 's2p2a_q10', 's2p2b_qa', 's2p2b_q1', 's2p2b_q2', 's2p2b_q3', 's2p2b_q4', \n",
    "    's2p2b_q5', 's2p2b_q6', 's2p2b_q7', 's2p2b_q8', 's2p2b_q9', 's2p2b_q10'\n",
    "]\n",
    "\n",
    "mapping_2013 = [\n",
    "    'hid', 'round', None, 'r_pid', 's2p2a_q1', 's2p2a_q2', 's2p2a_q3', 's2p2a_q4', 's2p2a_q5', 's2p2a_q6', \n",
    "    's2p2a_q7', 's2p2a_q8', 's2p2a_q9', 's2p2a_q10', None, 's2p2b_q1', 's2p2b_q2', 's2p2b_q3', 's2p2b_q4', \n",
    "    's2p2b_q5', 's2p2b_q6', 's2p2b_q7', 's2p2b_q8', 's2p2b_q9', 's2p2b_q10'\n",
    "]\n",
    "\n",
    "mapping_2014 = [\n",
    "    'hid', 'round', 's2p2a_qa', 'r_pid', 's2p2a_q1', 's2p2a_q2', 's2p2a_q3', 's2p2a_q4', 's2p2a_q5', 's2p2a_q6', \n",
    "    's2p2a_q7', 's2p2a_q8', 's2p2a_q9', 's2p2a_q10', 's2p2b_qa', 's2p2b_q1', 's2p2b_q2', 's2p2b_q3', 's2p2b_q4', \n",
    "    's2p2b_q5', 's2p2b_q6', 's2p2b_q7', 's2p2b_q8', 's2p2b_q9', 's2p2b_q10'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e2ad2c-cc58-4acf-9cb6-81d69c97d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "\n",
    "for col in mapping_2012:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)   \n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc4758c-27e7-49ff-91ee-63a09c4e2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col.strip()  # Remove leading/trailing whitespace\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if ref_col in df.columns:\n",
    "                    print(f\"Appending data for column {ref_col}\")\n",
    "                    if isinstance(df[ref_col], pd.Series):\n",
    "                        merged_data[ref_col].extend(df[ref_col].tolist())\n",
    "                    elif isinstance(df[ref_col], pd.DataFrame):\n",
    "                        print(f\"Column {ref_col} is duplicated in DataFrame. Appending data for each duplicate.\")\n",
    "                        for _, series in df[ref_col].items():\n",
    "                            merged_data[ref_col].extend(series.tolist())\n",
    "                else:\n",
    "                    print(f\"Column {ref_col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc7365b-da4a-472e-87bf-906e51e3204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['Unnamed: 0.1', 'Unnamed: 0', 'hid', 'round', 'r_pid', 's2p2a_qa', 's2p2a_q1', 's2p2a_q2', 's2p2a_q3', 's2p2a_q4', 's2p2a_q5', 's2p2a_q6', 's2p2a_q7', 's2p2a_q8', 's2p2a_q9', 's2p2a_q10', 's2p2b_qa', 's2p2b_q1', 's2p2b_q2', 's2p2b_q3', 's2p2b_q4', 's2p2b_q5', 's2p2b_q6', 's2p2b_q7', 's2p2b_q8', 's2p2b_q9', 's2p2b_q10']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column s2p2a_qa\n",
      "Appending data for column r_pid\n",
      "Appending data for column s2p2a_q1\n",
      "Appending data for column s2p2a_q2\n",
      "Appending data for column s2p2a_q3\n",
      "Appending data for column s2p2a_q4\n",
      "Appending data for column s2p2a_q5\n",
      "Appending data for column s2p2a_q6\n",
      "Appending data for column s2p2a_q7\n",
      "Appending data for column s2p2a_q8\n",
      "Appending data for column s2p2a_q9\n",
      "Appending data for column s2p2a_q10\n",
      "Appending data for column s2p2b_qa\n",
      "Appending data for column s2p2b_q1\n",
      "Appending data for column s2p2b_q2\n",
      "Appending data for column s2p2b_q3\n",
      "Appending data for column s2p2b_q4\n",
      "Appending data for column s2p2b_q5\n",
      "Appending data for column s2p2b_q6\n",
      "Appending data for column s2p2b_q7\n",
      "Appending data for column s2p2b_q8\n",
      "Appending data for column s2p2b_q9\n",
      "Appending data for column s2p2b_q10\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'r_pid', 's2p2a_q1', 's2p2a_q2', 's2p2a_q3', 's2p2a_q4', 's2p2a_q5', 's2p2a_q6', 's2p2a_q7', 's2p2a_q8', 's2p2a_q9', 's2p2a_q10', 's2p2b_q1', 's2p2b_q2', 's2p2b_q3', 's2p2b_q4', 's2p2b_q5', 's2p2b_q6', 's2p2b_q7', 's2p2b_q8', 's2p2b_q9', 's2p2b_q10']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column r_pid\n",
      "Appending data for column s2p2a_q1\n",
      "Appending data for column s2p2a_q2\n",
      "Appending data for column s2p2a_q3\n",
      "Appending data for column s2p2a_q4\n",
      "Appending data for column s2p2a_q5\n",
      "Appending data for column s2p2a_q6\n",
      "Appending data for column s2p2a_q7\n",
      "Appending data for column s2p2a_q8\n",
      "Appending data for column s2p2a_q9\n",
      "Appending data for column s2p2a_q10\n",
      "Appending data for column s2p2b_q1\n",
      "Appending data for column s2p2b_q2\n",
      "Appending data for column s2p2b_q3\n",
      "Appending data for column s2p2b_q4\n",
      "Appending data for column s2p2b_q5\n",
      "Appending data for column s2p2b_q6\n",
      "Appending data for column s2p2b_q7\n",
      "Appending data for column s2p2b_q8\n",
      "Appending data for column s2p2b_q9\n",
      "Appending data for column s2p2b_q10\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 's2p2a_qa', 'r_pid', 's2p2a_q1', 's2p2a_q2', 's2p2a_q3', 's2p2a_q4', 's2p2a_q5', 's2p2a_q6', 's2p2a_q7', 's2p2a_q8', 's2p2a_q9', 's2p2a_q10', 's2p2b_qa', 's2p2b_q1', 's2p2b_q2', 's2p2b_q3', 's2p2b_q4', 's2p2b_q5', 's2p2b_q6', 's2p2b_q7', 's2p2b_q8', 's2p2b_q9', 's2p2b_q10']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Appending data for column s2p2a_qa\n",
      "Appending data for column r_pid\n",
      "Appending data for column s2p2a_q1\n",
      "Appending data for column s2p2a_q2\n",
      "Appending data for column s2p2a_q3\n",
      "Appending data for column s2p2a_q4\n",
      "Appending data for column s2p2a_q5\n",
      "Appending data for column s2p2a_q6\n",
      "Appending data for column s2p2a_q7\n",
      "Appending data for column s2p2a_q8\n",
      "Appending data for column s2p2a_q9\n",
      "Appending data for column s2p2a_q10\n",
      "Appending data for column s2p2b_qa\n",
      "Appending data for column s2p2b_q1\n",
      "Appending data for column s2p2b_q2\n",
      "Appending data for column s2p2b_q3\n",
      "Appending data for column s2p2b_q4\n",
      "Appending data for column s2p2b_q5\n",
      "Appending data for column s2p2b_q6\n",
      "Appending data for column s2p2b_q7\n",
      "Appending data for column s2p2b_q8\n",
      "Appending data for column s2p2b_q9\n",
      "Appending data for column s2p2b_q10\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [df_2012, df_2013, df_2014]\n",
    "mappings = [mapping_2012, mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'hid': 'HID',\n",
    "    'round': 'Survey_Round',\n",
    "    's2p2a_qa': 'R_WOF',\n",
    "    'r_pid': 'PID',\n",
    "    's2p2a_q1': 'R_Sowing_HpD',\n",
    "    's2p2a_q2': 'R_Sowing_TD',\n",
    "    's2p2a_q3': 'R_Weeding_Hpd',\n",
    "    's2p2a_q4': 'R_Weeding_TD',\n",
    "    's2p2a_q5': 'R_Har_Hpd',\n",
    "    's2p2a_q6': 'R_Har_TD',\n",
    "    's2p2a_q7': 'R_PHA_Hpd',\n",
    "    's2p2a_q8': 'R_PHA_TD',\n",
    "    's2p2a_q9': 'R_OA_Hpd',\n",
    "    's2p2a_q10': 'R_OA_TD',\n",
    "    's2p2b_qa': 'K_WOF',\n",
    "    's2p2b_q1': 'K_Sowing_HpD',\n",
    "    's2p2b_q2': 'K_Sowing_TD',\n",
    "    's2p2b_q3': 'K_Weeding_Hpd',\n",
    "    's2p2b_q4': 'K_Weeding_TD',\n",
    "    's2p2b_q5': 'K_Har_Hpd',\n",
    "    's2p2b_q6': 'K_Har_TD',\n",
    "    's2p2b_q7': 'K_PHA_Hpd',\n",
    "    's2p2b_q8': 'K_PHA_TD',\n",
    "    's2p2b_q9': 'K_OA_Hpd',\n",
    "    's2p2b_q10': 'K_OA_TD'\n",
    "\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "'''\n",
    "# Drop redundant columns\n",
    "merged_df.drop(merged_df.columns[merged_df.columns.str.contains('Unnamed', case=True)], axis=1, inplace=True)\n",
    "merged_df.drop(merged_df.columns[merged_df.columns.str.contains(' ', case=False)], axis=1, inplace=True)\n",
    "'''\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('1. merged_EnI_Time Allocated to Own Farm Activities R&K).csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7835b-68d4-403c-a884-c36669ec385f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
