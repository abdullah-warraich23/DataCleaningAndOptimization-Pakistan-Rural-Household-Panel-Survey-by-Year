{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all male data across the years based on sections.\n",
    "There are datasets for 2012, 2012-1.5, 2013 and 2014\n",
    "The different sections that will be merged are as follows:\n",
    "**2012**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education (All men 18 and above)\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks\n",
    "10. Section 8: Community Participation and Social Network Membership\n",
    "\n",
    "**2013**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Health\n",
    "10. Section 8: Political Participation and Governance\n",
    "\n",
    "**2014**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks‚Äù\n",
    "10. Section 8: Participation in Social Safety Net\n",
    "11. Section 9: Siblings\n",
    "12. Section 10: Transfers\n",
    "13. Section 11: Health and Nutrition\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Store excel file locations to variables\n",
    "\n",
    "path_2012 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\15. Section 3 Part 2 Household Asset\\2012_s3p2_m.xlsx\"\n",
    "path_2012_5 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\15. Section 3 Part 2 Household Asset\\2012_5_s3p2.xlsx\"\n",
    "path_2013 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\15. Section 3 Part 2 Household Asset\\2013_s3p2_m.xlsx\"\n",
    "path_2014 = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\15. Section 3 Part 2 Household Asset\\2014_s3p2_m.xlsx\"\n",
    "# Read excel files \n",
    "df_2012 = pd.read_excel(path_2012)\n",
    "df_2012_5 = pd.read_excel(path_2012_5)\n",
    "df_2013 = pd.read_excel(path_2013)\n",
    "df_2014 = pd.read_excel(path_2014)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code block will be used to standardize column names across the years to avoid discrepancies during the merging process.\n",
    "\n",
    "# Rename columns in df_2013 to df_2014 column names\n",
    "\n",
    "df_2012.rename(columns={\n",
    "    'S3P2Q3': 's3p2_q2',\n",
    "    'S3P2Q4': 's3p2_q3',\n",
    "    'S3P2Q5': 's3p2_q4',\n",
    "    'PROVINCE_ID': 'P_ID',\n",
    "    'DISTRICT_ID': 'D_ID',\n",
    "    'TEHSIL_ID': 'T_ID',\n",
    "    'UC_ID': 'UC_ID\t',\n",
    "    'MAUZA_ID': 'M_ID'\n",
    "}, inplace=True)\n",
    "\n",
    "df_2012_5.rename(columns={\n",
    "    'Round': 'round',\n",
    "    'S3P2Q2': 'assets_id',\n",
    "    'S3P2_NAME': 'asset_name',\n",
    "    'S3P2Q3': 's3p2_q2',\n",
    "    'S3P2Q4': 's3p2_q3',\n",
    "    'S3P2Q5': 's3p2_q4',\n",
    "    'C_PROVINCE': 'P_ID',\n",
    "    'C_DISTRICT': 'D_ID',\n",
    "    'C_TEHSIL': 'T_ID',\n",
    "    'C_UC': 'UC_ID',\n",
    "    'C_MOUZA': 'M_ID',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "df_2013.rename(columns={\n",
    "\n",
    "    's3p2_q1': 'asset_name',\n",
    "    's3p2_q2': 's3p2_q2',\n",
    "    's3p2_q4': 's3p2_q3',\n",
    "    's3p2_q5': 's3p2_q4',\n",
    "    's3p2_q3': 'Ass_ALL_Part',\n",
    "    's3p2_q6': '2013_s3p2_q6',\n",
    "    's3p2_q7': '2013_s3p2_q7',\n",
    "    's3p2_q8': '2013_s3p2_q8',\n",
    "    's3p2_q9': '2013_s3p2_q9',\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce41949-4ca3-48f4-abc7-a8adf6ad6fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column mappings based on the provided positions\n",
    "# Make dictionaries for each year with updated names\n",
    "# replace with 'None' where there are no columns\n",
    "#Here are the updated mapping lists for the given datasets:\n",
    "\n",
    "\n",
    "mapping_2012 = [\n",
    "    \"hid\", \"round\", \"s3p1_sr\", \"None\", \"None\", \"s3p1_q2\", \"s3p1_q3\", \"s3p1_q4\",\n",
    "    \"s3p1_q5\", \"None\", \"None\", \"None\", \"None\", \"None\", \"P_ID\", \"D_ID\", \"T_ID\",\n",
    "    \"UC_ID\", \"M_ID\", \"None\", \"None\", \"None\", \"None\"\n",
    "]\n",
    "\n",
    "mapping_2012_5 = [\n",
    "    \"hid\", \"round\", \"s3p1_sr\", \"s3p1_name\", \"None\", \"None\", \"s3p1_q3\", \"s3p1_q4\",\n",
    "    \"s3p1_q5\", \"None\", \"None\", \"None\", \"None\", \"None\", \"P_ID\", \"D_ID\", \"T_ID\", \"UC_ID\", \n",
    "    \"M_ID\", \"C_HH_NUM\", \"Ass_Y_OldestU\", \"Ass_EP_Cap\", \"Ass_EP_U\"\n",
    "]\n",
    "\n",
    "mapping_2013 = [\n",
    "    \"hid\", \"round\", \"s3p1_sr\", \"s3p1_name\", \"None\", \"s3p1_q2\", \"s3p1_q3\", \"s3p1_q4\",\n",
    "    \"s3p1_q5\", \"s3p1_q6\", \"s3p1_q7\", \"s3p1_q8\", \"s3p1_q9\", \"Ass_ALL_Part\", \"None\",\n",
    "    \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\"\n",
    "]\n",
    "\n",
    "mapping_2014 = [\n",
    "    \"hid\", \"round\", \"s3p1_sr\", \"s3p1_name\", \"s3p1_q1\", \"s3p1_q2\", \"s3p1_q3\", \"s3p1_q4\",\n",
    "    \"s3p1_q5\", \"s3p1_q6\", \"s3p1_q7\", \"s3p1_q8\", \"s3p1_q9\", \"None\", \"None\", \"None\",\n",
    "    \"None\", \"None\", \"None\", \"None\", \"None\", \"None\", \"None\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ff0c33-1b53-44f3-8c0a-858987312571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "for col in mapping_2012:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2012_5:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5e935e-167a-4d75-99b2-0410c1a411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to standardize and merge DataFrames\n",
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if col in df.columns:\n",
    "                    print(f\"Appending data for column {col}\")\n",
    "                    merged_data[ref_col].extend(df[col].tolist())\n",
    "                else:\n",
    "                    print(f\"Column {col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdaad8d-94c6-4602-bc97-0315c84fe3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'asset_id', 's3p2_q2', 's3p2_q3', 's3p2_q4', 'P_ID', 'D_ID', 'T_ID', 'UC_ID\\t', 'M_ID']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Column s3p1_sr not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q2 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q3 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q4 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q5 not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Appending data for column P_ID\n",
      "Appending data for column D_ID\n",
      "Appending data for column T_ID\n",
      "Column UC_ID not found in DataFrame. Adding NaNs.\n",
      "Appending data for column M_ID\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'round', 'hid', 'P_ID', 'D_ID', 'T_ID', 'UC_ID', 'M_ID', 'C_HH_NUM', 'assets_id', 'asset_name', 's3p2_q2', 's3p2_q3', 's3p2_q4']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Column s3p1_sr not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_name not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q3 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q4 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q5 not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Appending data for column P_ID\n",
      "Appending data for column D_ID\n",
      "Appending data for column T_ID\n",
      "Appending data for column UC_ID\n",
      "Appending data for column M_ID\n",
      "Appending data for column C_HH_NUM\n",
      "Column Ass_Y_OldestU not found in DataFrame. Adding NaNs.\n",
      "Column Ass_EP_Cap not found in DataFrame. Adding NaNs.\n",
      "Column Ass_EP_U not found in DataFrame. Adding NaNs.\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'assets_id', 'asset_name', 's3p2_q2', 'Ass_ALL_Part', 's3p2_q3', 's3p2_q4', '2013_s3p2_q6', '2013_s3p2_q7', '2013_s3p2_q8', '2013_s3p2_q9']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Column s3p1_sr not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_name not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q2 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q3 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q4 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q5 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q6 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q7 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q8 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q9 not found in DataFrame. Adding NaNs.\n",
      "Appending data for column Ass_ALL_Part\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'hid', 'round', 'assets_id', 'asset_name', 's3p2_q1', 's3p2_q2', 's3p2_q3', 's3p2_q4', 's3p2_q5', 's3p2_q6', 's3p2_q7', 's3p2_q8', 's3p2_q9']\n",
      "Appending data for column hid\n",
      "Appending data for column round\n",
      "Column s3p1_sr not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_name not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q1 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q2 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q3 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q4 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q5 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q6 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q7 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q8 not found in DataFrame. Adding NaNs.\n",
      "Column s3p1_q9 not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n",
      "Column None not found in DataFrame. Adding NaNs.\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [df_2012, df_2012_5, df_2013, df_2014]\n",
    "mappings = [ mapping_2012, mapping_2012_5, mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'hid': 'HID',\n",
    "    'round': 'Survey_Round',\n",
    "    'assets_id': 'Ass_C',\n",
    "    'asset_name': 'Ass_N',\n",
    "    's3p2_q1': 'Ass_PR',\n",
    "    's3p2_q2': 'Ass_CR',\n",
    "    's3p2_q3': 'Ass_HH_no',\n",
    "    's3p2_q4': 'Ass_Val_T',\n",
    "    's3p2_q5': 'Ass_Rep',\n",
    "    's3p2_q6': 'Ass_S',\n",
    "    's3p2_q7': 'Ass_S_Val',\n",
    "    's3p2_q8': 'Ass_P',\n",
    "    's3p2_q9': 'Ass_P_Val'\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('merged_Section_3_part_2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a984fb-cef4-4d9e-9ac9-b680d6f41940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
