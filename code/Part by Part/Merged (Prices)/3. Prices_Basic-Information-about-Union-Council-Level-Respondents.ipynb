{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all PRICES data across the years based on sections.\n",
    "There are datasets for 2012, 2013 and 2014\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedd007-e29c-4664-8c47-81875441e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following code block will merge all \"Basic Information about union council Respondents\" files across the years.\n",
    "* First, we are going to read the respective files and store them as data frames\n",
    "* Next, we are going to define column mappings that I have already figured out via manual methods\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b06248f4-d50e-4ac4-9a12-91213643d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block stores file paths to variables to make the code neat\n",
    "# The stored variables are called in the read_excel function and stored as dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Store excel file locations to variables (change it as per your path to file)\n",
    "\n",
    "path_2013=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\PriceMerge\\1. Merging by Parts\\3. Section 1 Part 2 Basic Information about Union Council Level Respondents\\2013_s1p2_prices.csv\"\n",
    "path_2014=r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\PriceMerge\\1. Merging by Parts\\3. Section 1 Part 2 Basic Information about Union Council Level Respondents\\2014_s1p2_prices.csv\"\n",
    "\n",
    "# Read csv files\n",
    "\n",
    "df_2013 = pd.read_csv(path_2013)\n",
    "df_2014 = pd.read_csv(path_2014)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a81876-e34e-4771-b3fd-060be59fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code block will standardize column names across the years to avoid discrepancies during the merging process.\n",
    "For example, the cover data for 2013 is noth the same as in 2014 data, but they have the same data under their differently named variables. Hence, we decide to rename such columns beforehand\n",
    "We will add the updated name to the mapping dictionaries instead of the original names.\n",
    "'''\n",
    "\n",
    "# Rename columns in df_2013\n",
    "df_2013.rename(columns={\n",
    "    's1p2_q7' : 'UCLR_STI',\n",
    "    's1p2_q8' : 'UCLR_ETI',\n",
    "    's1p2_q9' : 'UCLR_DOI' \n",
    "}, inplace=True)\n",
    "\n",
    "# df_2014 doesn't need renaming as it is the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee7fb3b4-574e-4f18-a759-92b1d39f205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated mappings\n",
    "mapping_2013 = [\n",
    "    'cid', 'round', 's1p2_q1', None, None, None, None, None, None, None, None, 'UCLR_STI', 'UCLR_ETI', 'UCLR_DOI'\n",
    "]\n",
    "\n",
    "mapping_2014 = [\n",
    "    'cid', 'round', 's1p2_q1', 's1p2_q6_c', 's1p2_q7_hh', 's1p2_q7_mm',\n",
    "    's1p2_q8_hh', 's1p2_q8_mm', 's1p2_q9_dd', 's1p2_q9_mm', 's1p2_q9_yy',\n",
    "    None, None, None\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bdd3969-3848-486d-af74-f8970359b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all possible columns in the correct order\n",
    "all_columns = []\n",
    "\n",
    "for col in mapping_2013:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "for col in mapping_2014:\n",
    "    if col and col not in all_columns:\n",
    "        all_columns.append(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e94ea101-d44f-410d-b66e-385775a40df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def standardize_and_merge(dfs, mappings, all_columns):\n",
    "    merged_data = {col: [] for col in all_columns}\n",
    "\n",
    "    for df, mapping in zip(dfs, mappings):\n",
    "        print(f\"Processing DataFrame with columns: {df.columns.tolist()}\")\n",
    "        for i, col in enumerate(mapping):\n",
    "            if col:\n",
    "                ref_col = col.strip()  # Remove leading/trailing whitespace\n",
    "                if ref_col not in merged_data:\n",
    "                    merged_data[ref_col] = []\n",
    "                if ref_col in df.columns:\n",
    "                    print(f\"Appending data for column {ref_col}\")\n",
    "                    if isinstance(df[ref_col], pd.Series):\n",
    "                        merged_data[ref_col].extend(df[ref_col].tolist())\n",
    "                    elif isinstance(df[ref_col], pd.DataFrame):\n",
    "                        print(f\"Column {ref_col} is duplicated in DataFrame. Appending data for each duplicate.\")\n",
    "                        for _, series in df[ref_col].items():\n",
    "                            merged_data[ref_col].extend(series.tolist())\n",
    "                else:\n",
    "                    print(f\"Column {ref_col} not found in DataFrame. Adding NaNs.\")\n",
    "                    merged_data[ref_col].extend([np.nan] * len(df))\n",
    "    \n",
    "    max_len = max(len(v) for v in merged_data.values())\n",
    "    for key in merged_data:\n",
    "        col_len = len(merged_data[key])\n",
    "        if col_len < max_len:\n",
    "            merged_data[key].extend([np.nan] * (max_len - col_len))\n",
    "\n",
    "    merged_df = pd.DataFrame.from_dict(merged_data)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3f20b62-3d2f-4c24-b161-c2dd63f1dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame with columns: ['cid', 'round', 's1_part_no', 's1p2_q1', 'UCLR_STI', 'UCLR_ETI', 'UCLR_DOI']\n",
      "Appending data for column cid\n",
      "Appending data for column round\n",
      "Appending data for column s1p2_q1\n",
      "Appending data for column UCLR_STI\n",
      "Appending data for column UCLR_ETI\n",
      "Appending data for column UCLR_DOI\n",
      "Processing DataFrame with columns: ['Unnamed: 0', 'cid', 'round', 's1p2_q1', 's1p2_q6_c', 's1p2_q7_hh', 's1p2_q7_mm', 's1p2_q8_hh', 's1p2_q8_mm', 's1p2_q9_dd', 's1p2_q9_mm', 's1p2_q9_yy']\n",
      "Appending data for column cid\n",
      "Appending data for column round\n",
      "Appending data for column s1p2_q1\n",
      "Appending data for column s1p2_q6_c\n",
      "Appending data for column s1p2_q7_hh\n",
      "Appending data for column s1p2_q7_mm\n",
      "Appending data for column s1p2_q8_hh\n",
      "Appending data for column s1p2_q8_mm\n",
      "Appending data for column s1p2_q9_dd\n",
      "Appending data for column s1p2_q9_mm\n",
      "Appending data for column s1p2_q9_yy\n"
     ]
    }
   ],
   "source": [
    "# Usage with dataframes and mappings\n",
    "dfs = [df_2013, df_2014]\n",
    "mappings = [mapping_2013, mapping_2014]\n",
    "\n",
    "merged_df = standardize_and_merge(dfs, mappings, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51a5aad7-5898-4f02-948f-c3bcced01f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for the merged file (if needed)\n",
    "rename_mapping = {\n",
    "    'cid': 'CID',\n",
    "    'round': 'Survey_Round',\n",
    "    's1p2_q1': 'UCLR_Shop_Type',\n",
    "    's1p2_q6_c': 'UCLR_Caste',\n",
    "    's1p2_q7_hh': 'UCLR_STI_hrs',\n",
    "    's1p2_q7_mm': 'UCLR_STI_min',\n",
    "    's1p2_q8_hh': 'UCLR_ETI_hrs',\n",
    "    's1p2_q8_mm': 'UCLR_ETI_min',\n",
    "    's1p2_q9_dd': 'UCLR_DOI_d',\n",
    "    's1p2_q9_mm': 'UCLR_DOI_m',\n",
    "    's1p2_q9_yy': 'UCLR_DOI_y'\n",
    "}\n",
    "\n",
    "merged_df.rename(columns=rename_mapping, inplace=True)\n",
    "\n",
    "# Save the merged dataframe to a CSV file\n",
    "merged_df.to_csv('merged_Prices_Basic-Information-about-Union-Council-Level-Respondents.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7835b-68d4-403c-a884-c36669ec385f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
