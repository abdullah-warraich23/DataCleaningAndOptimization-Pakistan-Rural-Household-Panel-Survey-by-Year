{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e877b5-ee61-4e99-a33b-dcb46ee3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook contains the code to merge all male data across the years based on sections.\n",
    "There are datasets for 2012, 2012-1.5, 2013 and 2014\n",
    "The different sections that will be merged are as follows:\n",
    "**2012**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education (All men 18 and above)\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks\n",
    "10. Section 8: Community Participation and Social Network Membership\n",
    "\n",
    "**2013**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Health\n",
    "10. Section 8: Political Participation and Governance\n",
    "\n",
    "**2014**\n",
    "1. Cover\n",
    "2. Roaster\n",
    "3. Section 1: Education: Males 19 years and older\n",
    "4. Section 2: Agriculture\n",
    "5. Section 3: Assets\n",
    "6. Section 4: Consumption and Expenditure\n",
    "7. Section 5: Credit\n",
    "8. Section 6: Employment and Income\n",
    "9. Section 7: Economic Events/Shocks‚Äù\n",
    "10. Section 8: Participation in Social Safety Net\n",
    "11. Section 9: Siblings\n",
    "12. Section 10: Transfers\n",
    "13. Section 11: Health and Nutrition\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606eb06-a5d4-4b00-aa0f-37dc3ce09185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "13dc2f38-e53b-4f85-98e9-98c1f975e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path where the data files are located\n",
    "data_folder = r\"C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\"\n",
    "\n",
    "# List of all the file names to be merged\n",
    "file_names = ['1. merged_roster.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb59a1c-173b-4188-9b5e-7ec3de5f4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "The following 3 cells do the same thing but on different levels. to summarize:\n",
    "\n",
    "    * Merges multiple CSV files based on specified merge keys.\n",
    "\n",
    "    * Parameters:\n",
    "     - data_folder (str): The folder path where the data files are located.\n",
    "     - file_names (list of str): List of all the file names to be merged.\n",
    "     - output_file (str): The name of the output file where merged data will be saved.\n",
    "     - merge_keys (list of str): List of keys to merge the data on.\n",
    "\n",
    "    * Returns:\n",
    "     - None\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e53b5e80-68e5-4d4a-a5f5-75f25ca54375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\1. merged_roster.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\1. merged_roster.csv\n",
      "Merged data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#'HID', 'PID' Level\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the list, read it, and concatenate it to the merged DataFrame\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)  # Create the full file path\n",
    "    print(f\"Looking for file: {file_path}\")  # Debug print\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")  # Debug print\n",
    "        df = pd.read_csv(file_path, dtype=str)  # Read the CSV file with all columns as strings to handle mixed data types\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)  # Concatenate the current file's data to the merged DataFrame\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")  # Debug print\n",
    "\n",
    "# Proceed only if merged_df is not empty\n",
    "if not merged_df.empty:\n",
    "    # Define the merge keys\n",
    "    merge_keys = ['HID', 'PID']\n",
    "    # Filter out merge keys that are not in the DataFrame\n",
    "    available_merge_keys = [key for key in merge_keys if key in merged_df.columns]\n",
    "\n",
    "    # Reorder columns to have available merge keys first and then the rest alphabetically\n",
    "    remaining_columns = [col for col in merged_df.columns if col not in available_merge_keys]  # Get columns excluding available merge keys\n",
    "    # Sort the remaining columns alphabetically; put columns starting with digits at the end\n",
    "    sorted_columns = sorted(remaining_columns, key=lambda x: (x[0].isdigit(), x))\n",
    "\n",
    "    # Define the final column order with available merge keys first\n",
    "    column_order = available_merge_keys + sorted_columns\n",
    "    # Reorder the DataFrame columns according to the defined order\n",
    "    merged_df = merged_df[column_order]\n",
    "\n",
    "    # Remove columns that are entirely empty\n",
    "    merged_df.dropna(axis=1, how='all', inplace=True)\n",
    "    # Remove rows that are entirely empty\n",
    "    merged_df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    # Save the merged and processed data to a new CSV file\n",
    "    merged_df.to_csv('1. Roaster_Household-HouseholdMember_Level.csv', index=False)\n",
    "    print(\"Merged data saved successfully!\")\n",
    "else:\n",
    "    print(\"No data to merge and save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "32ed9748-ec7c-4d9e-bc16-2cda489985f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\1. merged_EEnS_Negative Economic Event.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\1. merged_EEnS_Negative Economic Event.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\2. merged_EEnS_Positive Economic Event.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\2. merged_EEnS_Positive Economic Event.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\3. merged_EEnS_Floods - Overview.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\3. merged_EEnS_Floods - Overview.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\4. merged_EEnS_2012s9p2.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\4. merged_EEnS_2012s9p2.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\5. merged_EEnS_Conflict Events.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\5. merged_EEnS_Conflict Events.csv\n",
      "Merged data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#'HID', 'PID', 'Plt_ID', 'Crop_ID', 'Season' Level\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the list, read it, and concatenate it to the merged DataFrame\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)  # Create the full file path\n",
    "    print(f\"Looking for file: {file_path}\")  # Debug print\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")  # Debug print\n",
    "        df = pd.read_csv(file_path, dtype=str)  # Read the CSV file with all columns as strings to handle mixed data types\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)  # Concatenate the current file's data to the merged DataFrame\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")  # Debug print\n",
    "\n",
    "# Proceed only if merged_df is not empty\n",
    "if not merged_df.empty:\n",
    "    # Define the merge keys\n",
    "    merge_keys = ['HID', 'PID', 'Plt_ID', 'Crop_ID', 'Season']\n",
    "    # Filter out merge keys that are not in the DataFrame\n",
    "    available_merge_keys = [key for key in merge_keys if key in merged_df.columns]\n",
    "\n",
    "    # Reorder columns to have available merge keys first and then the rest alphabetically\n",
    "    remaining_columns = [col for col in merged_df.columns if col not in available_merge_keys]  # Get columns excluding available merge keys\n",
    "    # Sort the remaining columns alphabetically; put columns starting with digits at the end\n",
    "    sorted_columns = sorted(remaining_columns, key=lambda x: (x[0].isdigit(), x))\n",
    "\n",
    "    # Define the final column order with available merge keys first\n",
    "    column_order = available_merge_keys + sorted_columns\n",
    "    # Reorder the DataFrame columns according to the defined order\n",
    "    merged_df = merged_df[column_order]\n",
    "\n",
    "    # Remove columns that are entirely empty\n",
    "    merged_df.dropna(axis=1, how='all', inplace=True)\n",
    "    # Remove rows that are entirely empty\n",
    "    merged_df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    # Save the merged and processed data to a new CSV file\n",
    "    merged_df.to_csv('8.1. EconomicEventsAndShocks_Household-HouseholdMember-PlotID-CropID-Season_Level.csv', index=False)\n",
    "    print(\"Merged data saved successfully!\")\n",
    "else:\n",
    "    print(\"No data to merge and save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce463f21-71b0-446f-ba9c-2f3205ba341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\1. merged_EEnS_Negative Economic Event.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\1. merged_EEnS_Negative Economic Event.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\2. merged_EEnS_Positive Economic Event.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\2. merged_EEnS_Positive Economic Event.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\3. merged_EEnS_Floods - Overview.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\3. merged_EEnS_Floods - Overview.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\4. merged_EEnS_2012s9p2.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\4. merged_EEnS_2012s9p2.csv\n",
      "Looking for file: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\5. merged_EEnS_Conflict Events.csv\n",
      "File found: C:\\Users\\warra\\Desktop\\Freelance\\data\\data\\MaleMerge\\2. ALL MERGED CSV Parts\\8. Economic events and Shocks\\5. merged_EEnS_Conflict Events.csv\n",
      "Merged data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#'HID', 'Season', 'Shock_ID' Level\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize an empty DataFrame to hold the merged data\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the list, read it, and concatenate it to the merged DataFrame\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_folder, file_name)  # Create the full file path\n",
    "    print(f\"Looking for file: {file_path}\")  # Debug print\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")  # Debug print\n",
    "        df = pd.read_csv(file_path, dtype=str)  # Read the CSV file with all columns as strings to handle mixed data types\n",
    "        merged_df = pd.concat([merged_df, df], ignore_index=True)  # Concatenate the current file's data to the merged DataFrame\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")  # Debug print\n",
    "\n",
    "# Proceed only if merged_df is not empty\n",
    "if not merged_df.empty:\n",
    "    # Define the merge keys\n",
    "    merge_keys = ['HID', 'Season', 'Shock_ID']\n",
    "    # Filter out merge keys that are not in the DataFrame\n",
    "    available_merge_keys = [key for key in merge_keys if key in merged_df.columns]\n",
    "\n",
    "    # Reorder columns to have available merge keys first and then the rest alphabetically\n",
    "    remaining_columns = [col for col in merged_df.columns if col not in available_merge_keys]  # Get columns excluding available merge keys\n",
    "    # Sort the remaining columns alphabetically; put columns starting with digits at the end\n",
    "    sorted_columns = sorted(remaining_columns, key=lambda x: (x[0].isdigit(), x))\n",
    "\n",
    "    # Define the final column order with available merge keys first\n",
    "    column_order = available_merge_keys + sorted_columns\n",
    "    # Reorder the DataFrame columns according to the defined order\n",
    "    merged_df = merged_df[column_order]\n",
    "\n",
    "    # Remove columns that are entirely empty\n",
    "    merged_df.dropna(axis=1, how='all', inplace=True)\n",
    "    # Remove rows that are entirely empty\n",
    "    merged_df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    # Save the merged and processed data to a new CSV file\n",
    "    merged_df.to_csv('8.2. EconomicEventsAndShocks_Household-Season-ShockType_Level.csv', index=False)\n",
    "    print(\"Merged data saved successfully!\")\n",
    "else:\n",
    "    print(\"No data to merge and save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d9496-959f-4eec-8c8d-25cec4fcb520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
